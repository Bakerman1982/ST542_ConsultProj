---
title: "Bridging the Gap:"
subtitle: "Comparing Employer and Educator Expectations in Small Animal Dentistry"
author: Brock Akerman, Hanan Ali, Taylor Cesarski
date: "June, 25, 2025"
format:
  pdf:
    pdf-engine: xelatex
    mainfont: "Times New Roman"
    toc: true
    toc-depth: 2
    number-sections: true
    fig-align: center
    fig-cap-location: top
    fig-pos: 'H'
    geometry: margin=1in
    fontsize: 11pt
    keep-tex: true
    linkcolor: blue
---

```{r package_load, warning=FALSE, include=FALSE}
library(ggplot2)
library(tidyverse)
library(janitor)
library(gtools)
library(naniar)
```

```{r Employer Data load, echo=FALSE, message=FALSE, warning=FALSE, results="hide",include=FALSE, error=FALSE}
#############################################
## Connect, Import, group and primary key. ##
#############################################

#Read data into R environment. 
Employer_Data <- read_csv("Employer_Dentistry_Survey.csv") %>% clean_names()
#Name new object to work with leaving original intact/untouched
Employer_Data_Clean <- Employer_Data

#Add grouping identifier now so if we combine data later, we have our groups delineated. 
Employer_Data_Clean <- Employer_Data_Clean %>%
  mutate(
    group = "Employer", #Categorizes all responses as Employer
    respondent_id = row_number() #Maintains respondent ID
  )


############################
#####  DATA WRANGLING  #####
############################

#Adjust headers for readability and add grouping identifier.
#1.) Remove redundancy in column names, 
#2.) Replace "quid" with "Q", and
#3.) All "_text" with "T".
colnames(Employer_Data_Clean) <- gsub("_text$", "_T", gsub("q", "Q", colnames(Employer_Data_Clean)))
#4.) Format the column headers so that it is sort-able both by question and sub question. So where 
#questions are formatted with header Q10_2, the header will now be Q10_02.  This preserves ordering
#and makes indexing easier. 
emp_pad_question_ids <- function(col_names) {
  col_names %>%
    str_replace_all("Q(\\d{1})(?!\\d)", "Q0\\1") %>%
    str_replace_all("Q(\\d{2})_(\\d{1})(?!\\d)", "Q\\1_0\\2")}

#Apply above formatting changes to data frame column names
colnames(Employer_Data_Clean) <- emp_pad_question_ids(colnames(Employer_Data_Clean))

#Removes Qualtric metadata from the first two rows
Employer_Data_Clean <- Employer_Data_Clean %>% slice(-1, -2)



### QUESTION-BY-QUESTION Cleaning

#------------
#Question #04
#------------
#Renames the text response to index 13 and places it in its order. 
Employer_Data_Clean <- Employer_Data_Clean %>%
  rename(Q04_13 = Q04_12_T)

#------------
#Question #09 does not need correcting. 
#------------

#------------
#Question #16
#------------
#Renames the text response to index 11 and places it in its order. 
Employer_Data_Clean <- Employer_Data_Clean %>%
  rename(Q16_11 = Q16_10_T) 

#Process Q12: Split responses and pivot to wide format
Employer_Data_Clean <- Employer_Data_Clean %>%
  mutate(respondent_id = row_number()) %>%
  separate_rows(Q16, sep = ",") %>%
  mutate(Q16 = str_trim(Q16)) %>%
  #filter(!is.na(Q16)) %>%  # üîß prevent Q16_NA column in pivot_wider
  mutate(Q16 = str_pad(Q16, width = 2, pad = "0"),
         value = 1) %>%
  pivot_wider(
    names_from = Q16,
    names_prefix = "Q16_",
    values_from = value,
    values_fill = 0
  ) %>%
  right_join(select(Employer_Data_Clean, respondent_id), by = "respondent_id")  # üîÅ bring back NA responders


if (!"Q16_09" %in% colnames(Employer_Data_Clean)) {
  Employer_Data_Clean$Q16_09 <- 0
}


#------------
#Question #17
#------------
#Renames the text response to index 14 and places it in its order.
Employer_Data_Clean <- Employer_Data_Clean %>%
  rename(Q17_15 = Q17_14_T)

#------------
#Question #20
#------------
# Create binary indicator columns from Q16.  Recall that Q16 was a multiple responsive
# "Select all that Apply" question where participants could choose however many they 
# wanted.  In the Qualtrics output, these responses were comma-separated.  This query
# breaks each reponse out over a column and assigns values of "0" or "1" depending on 
# whether they choose that particular response. The same issue is address in Question #20. 
Q20_binary <- Employer_Data_Clean %>%
  select(respondent_id, Q20) %>%
  separate_rows(Q20, sep = ",") %>%
  mutate(Q20 = str_trim(Q20)) %>%
  #filter(!is.na(Q20)) %>%   # üëà Prevents Q20_NA from being created
  mutate(Q20 = str_pad(Q20, width = 2, pad = "0"),
         value = 1) %>%
  pivot_wider(
    names_from = Q20,
    names_prefix = "Q20_",
    values_from = value,
    values_fill = 0
  ) %>%
  right_join(select(Employer_Data_Clean, respondent_id), by = "respondent_id")

# Remove the old Q16 columns and join the binary ones on respondent_id
Employer_Data_Clean <- Employer_Data_Clean %>%
  select(-Q20) %>%
  left_join(Q20_binary, by = "respondent_id")

# Renames the text response to index 07 and places it in its order.
Employer_Data_Clean <- Employer_Data_Clean %>%
  rename(Q20_07 = Q20_06_T) %>%
  relocate(Q20_07, .after = Q20_06)

# Add Q16_05 as a column of zeros if it doesn't exist (it does not)
if (!"Q20_05" %in% colnames(Employer_Data_Clean)) {
  Employer_Data_Clean$Q20_05 <- 0
}

#------------
#Question #21
#------------
#Renames the text response to index 07 and places it in its order.
Employer_Data_Clean <- Employer_Data_Clean %>%
  rename(Q21_07 = Q21_06_T) 

#------------
#Question #22 does not need correcting. 
#------------

#------------
#Question #24 does not need correcting. 
#------------

#------------
#Question #25
#------------
# Create binary indicator columns from Q25.  Recall that Q25 was a multiple responsive
# "Select all that Apply" question where participants could choose however many they 
# wanted.  In the Qualtrics output, these responses were comma-separated.  This query
# breaks each reponse out over a column and assigns values of "0" or "1" depending on 
# whether they choose that particular response. The same issue is address in Question #16. 
Q25_binary <- Employer_Data_Clean %>%
  select(respondent_id, Q25) %>%
  separate_rows(Q25, sep = ",") %>%
  mutate(Q25 = str_trim(Q25)) %>%
  #filter(!is.na(Q25)) %>%   # üëà Prevents Q25_NA
  mutate(Q25 = str_pad(Q25, width = 2, pad = "0"),
         value = 1) %>%
  pivot_wider(
    names_from = Q25,
    names_prefix = "Q25_",
    values_from = value,
    values_fill = 0
  ) %>%
  right_join(select(Employer_Data_Clean, respondent_id), by = "respondent_id")


# Remove the old Q16 columns and join the binary ones in
Employer_Data_Clean <- Employer_Data_Clean %>%
  select(-Q25) %>%
  left_join(Q25_binary, by = "respondent_id")

# Add Q25_13 as a column of zeros if it doesn't exist (it does not)
if (!"Q25_13" %in% colnames(Employer_Data_Clean)) {
  Employer_Data_Clean$Q25_13 <- 0
}

# Rename and relocate the "Other" text entry for Q16
Employer_Data_Clean <- Employer_Data_Clean %>%
  rename(Q25_14 = Q25_13_T) %>%
  relocate(Q25_14, .after = Q25_13)

#------------
#Question #26
#------------
#Renames the text response to index 14 and places it in its order. 
Employer_Data_Clean <- Employer_Data_Clean %>%
  rename(Q26_14 = Q26_13_T) 


##########################
##### FILTER DATASET #####
##########################
#"Q20_NA"
#"Q25_NA"


#Remove irrelevant/problematic columns to the research/stats questions
Employer_Data_Clean <- Employer_Data_Clean %>%
  mutate(progress = as.numeric(progress)) %>%
  filter(Q02 == '1', progress >= 50) %>%
  select(
    ip_address, progress, duration_in_seconds,
    finished, recorded_date, response_id, group, respondent_id,
    starts_with("Q04"),
    starts_with("Q09"),
    starts_with("Q16"),
    starts_with("Q17"),
    starts_with("Q20"),
    starts_with("Q21"),
    starts_with("Q22"),
    starts_with("Q24"),
    starts_with("Q25"),
    starts_with("Q26"),
    -Q16_NA,  # üëà drop this
    -Q20_NA,  # üëà drop this
    -Q25_NA
  )

#Identify metadata columns to keep at the front
emp_meta_cols <- c("ip_address", "progress", "duration_in_seconds",
               "finished", "recorded_date", "response_id", "group", "respondent_id")

#Identify and sort Q columns using mixedsort
emp_q_cols <- setdiff(colnames(Employer_Data_Clean), emp_meta_cols)
emp_q_cols_sorted <- mixedsort(emp_q_cols)

#Reorder the data frame
Employer_Data_Clean <- Employer_Data_Clean[, c(emp_meta_cols, emp_q_cols_sorted)]
```

```{r Educator Data load, echo=FALSE, message=FALSE, warning=FALSE, results="hide",include=FALSE, error=FALSE}
#############################################
## Connect, Import, group and primary key. ##
#############################################

#Read data into R environment. 
Educator_Data <- read_csv("PCVE_Dentistry_Survey.csv") %>% clean_names()
#Name new object to work with leaving original intact/untouched
Educator_Data_Clean <- Educator_Data

#Add identifier affirming educator responses. 
Educator_Data_Clean <- Educator_Data_Clean %>%
  mutate(
    group = "Educator",
    respondent_id = row_number()
  )

############################
#####  DATA WRANGLING  #####
############################

#Adjust headers for readability and add grouping identifier.
  #1.) Remove redundancy in column names, 
  #2.) Replace "quid" with "Q", and
  #3.) All "_text" with "T".
colnames(Educator_Data_Clean) <- gsub("_text$", "_T", gsub("q", "Q", colnames(Educator_Data_Clean)))
  #4.) Format the column headers so that it is sort-able both by question and sub question. So where 
    #questions are formatted with header Q10_2, the header will now be Q10_02.  This preserves ordering
    #and makes indexing easier. 
edu_pad_question_ids <- function(col_names) {
  col_names %>%
    str_replace_all("Q(\\d{1})(?!\\d)", "Q0\\1") %>%
    str_replace_all("Q(\\d{2})_(\\d{1})(?!\\d)", "Q\\1_0\\2")}

#Apply above formatting changes to data frame column names
colnames(Educator_Data_Clean) <- edu_pad_question_ids(colnames(Educator_Data_Clean))

#Removes Qualtric metadata from the first two rows
Educator_Data_Clean <- Educator_Data_Clean %>% slice(-1, -2)


### QUESTION-BY-QUESTION Cleaning

#------------
#Question #04
#------------
#Renames the text response to index 13 and places it in its order. 
Educator_Data_Clean <- Educator_Data_Clean %>%
  rename(Q04_13 = Q04_12_T)

#------------
#Question #07 does not need correcting. 
#------------

#------------
#Question #12
#------------
  #Renames the text response to index 11 and places it in its order. 
Educator_Data_Clean <- Educator_Data_Clean %>%
  rename(Q12_11 = Q12_10_T) 

  #Process Q12: Split responses and pivot to wide format
Educator_Data_Clean <- Educator_Data_Clean %>%
  # Create a temporary respondent ID if not already done
  mutate(respondent_id = row_number()) %>%
  # Separate comma-separated values into long format
  separate_rows(Q12, sep = ",") %>%
  # Trim whitespace if any
  mutate(Q12 = str_trim(Q12)) %>%
  # Pad values with leading zero for consistent column naming (01, 02, ..., 11)
  mutate(Q12 = str_pad(Q12, width = 2, pad = "0"),
         value = 1) %>%
  # Pivot wider to get binary indicator columns
  pivot_wider(
    names_from = Q12,
    names_prefix = "Q12_",
    values_from = value,
    values_fill = 0
  )

#------------
#Question #13
#------------
#Renames the text response to index 14 and places it in its order.
Educator_Data_Clean <- Educator_Data_Clean %>%
  rename(Q13_14 = Q13_13_T)

#------------
#Question #16
#------------
# Create binary indicator columns from Q16.  Recall that Q16 was a multiple responsive
# "Select all that Apply" question where participants could choose however many they 
# wanted.  In the Qualtrics output, these responses were comma-separated.  This query
# breaks each reponse out over a column and assigns values of "0" or "1" depending on 
# whether they choose that particular response. The same issue is address in Question #20. 
Q16_binary <- Educator_Data_Clean %>%
  select(respondent_id, Q16) %>%
  separate_rows(Q16, sep = ",") %>%
  mutate(Q16 = str_trim(Q16)) %>%
  mutate(Q16 = str_pad(Q16, width = 2, pad = "0"),
         value = 1) %>%
  pivot_wider(
    names_from = Q16,
    names_prefix = "Q16_",
    values_from = value,
    values_fill = 0
  )

  # Remove the old Q16 columns and join the binary ones on respondent_id
Educator_Data_Clean <- Educator_Data_Clean %>%
  select(-Q16) %>%
  left_join(Q16_binary, by = "respondent_id")

  # Renames the text response to index 07 and places it in its order.
Educator_Data_Clean <- Educator_Data_Clean %>%
  rename(Q16_07 = Q16_06_T) %>%
  relocate(Q16_07, .after = Q16_06)

  # Add Q16_05 as a column of zeros if it doesn't exist (it does not)
if (!"Q16_05" %in% colnames(Educator_Data_Clean)) {
  Educator_Data_Clean$Q16_05 <- 0
}

#------------
#Question #17
#------------
#Renames the text response to index 07 and places it in its order.
Educator_Data_Clean <- Educator_Data_Clean %>%
  rename(Q17_07 = Q17_06_T) 

#------------
#Question #18 does not need correcting. 
#------------

#------------
#Question #19 does not need correcting. 
#------------

#------------
#Question #20
#------------
# Create binary indicator columns from Q16.  Recall that Q16 was a multiple responsive
# "Select all that Apply" question where participants could choose however many they 
# wanted.  In the Qualtrics output, these responses were comma-separated.  This query
# breaks each reponse out over a column and assigns values of "0" or "1" depending on 
# whether they choose that particular response. The same issue is address in Question #16. 
Q20_binary <- Educator_Data_Clean %>%
  select(respondent_id, Q20) %>%
  separate_rows(Q20, sep = ",") %>%
  mutate(Q20 = str_trim(Q20)) %>%
  mutate(Q20 = str_pad(Q20, width = 2, pad = "0"),
         value = 1) %>%
  pivot_wider(
    names_from = Q20,
    names_prefix = "Q20_",
    values_from = value,
    values_fill = 0
  )

# Remove the old Q16 columns and join the binary ones in
Educator_Data_Clean <- Educator_Data_Clean %>%
  select(-Q20) %>%
  left_join(Q20_binary, by = "respondent_id")

# Rename and relocate the "Other" text entry for Q16
Educator_Data_Clean <- Educator_Data_Clean %>%
  rename(Q20_14 = Q20_13_T) %>%
  relocate(Q20_14, .after = Q20_13)

#------------
#Question #21
#------------
#Renames the text response to index 14 and places it in its order. 
Educator_Data_Clean <- Educator_Data_Clean %>%
  rename(Q21_14 = Q21_13_T) 


##########################
##### FILTER DATASET #####
##########################

#Remove irrelevant/problematic columns to the research/stats questions
Educator_Data_Clean <- Educator_Data_Clean %>%
  mutate(progress = as.numeric(progress)) %>%
  filter(Q44 != "2", progress >= 50) %>%
  select(
    ip_address, progress, duration_in_seconds,
    finished, recorded_date, response_id, group, respondent_id,
    starts_with("Q04"),
    starts_with("Q07"),
    starts_with("Q12"),
    starts_with("Q13"),
    starts_with("Q16"),
    starts_with("Q17"),
    starts_with("Q18"),
    starts_with("Q19"),
    starts_with("Q20"),
    starts_with("Q21")
  )



#Identify metadata columns to keep at the front
edu_meta_cols <- c("ip_address", "progress", "duration_in_seconds",
               "finished", "recorded_date", "response_id", "group", "respondent_id")

#Identify and sort Q columns using mixedsort
edu_q_cols <- setdiff(colnames(Educator_Data_Clean), edu_meta_cols)
edu_q_cols_sorted <- mixedsort(edu_q_cols)

#Reorder the data frame
Educator_Data_Clean <- Educator_Data_Clean[, c(edu_meta_cols, edu_q_cols_sorted)]
```

# Abstract

# Introduction

## Purpose of project

## Study details

# Data

## Data Description

Two separate surveys were administered to mutually exclusive groups: veterinary employers who have worked with students, and educators who have taught those students. There was no overlap between these groups‚Äîno evidence suggests that any surveyed student was both taught by an educator and later employed by a participating employer.

The employer dataset consists of responses from 29 participants answering 40 questions, while the educator dataset includes 43 participants answering 34 questions. Each group was asked a single qualifying question to determine eligibility for participation, along with nine questions covering demographics and institutional context. Educators were then presented with 24 competency- and sentiment-based questions, while employers answered 30 such items focused on professional expectations and training in veterinary medicine.

Survey questions took several forms. Some were binary (Yes/No), particularly those related to demographics and institutional affiliation. Others used a "select all that apply" format, commonly seen in questions asking respondents to identify procedures performed at their practice. Many of these questions were followed by Likert-scale items. The Likert scales were even-numbered and omitted a neutral option, which may have contributed to at least two instances where respondents selected both ‚Äúagree‚Äù and ‚Äúdisagree‚Äù for the same item.

Several questions offered an ‚ÄúOther‚Äù response with a text box for elaboration. A few required numeric input, such as estimates of hours worked or the number of practicing veterinarians. These integer fields were not restricted by any upper bound, regardless of contextual reasonableness.

Survey completion time differed by group. Educators, on average, spent more time completing the survey than employers. While no follow-up question asked participants to explain their response time, this discrepancy may reflect greater engagement or a tendency for more elaborated responses among educators. It may also suggest a greater willingness among educators to participate more thoughtfully. The box plot below illustrates the distribution of survey duration (in minutes) by group.

```{r Data_Desc_01, echo=FALSE, fig.align='center'}
#Average time for survey completion
# Convert and clean both datasets
clean_employer <- Employer_Data[-c(1,2), ] %>%
  mutate(
    duration_in_seconds = as.numeric(duration_in_seconds),
    duration_minutes = duration_in_seconds / 60,
    group = "Employer"
  )

clean_educator <- Educator_Data[-c(1,2), ] %>%
  mutate(
    duration_in_seconds = as.numeric(duration_in_seconds),
    duration_minutes = duration_in_seconds / 60,
    group = "Educator"
  )

# Combine for optional single-geom plotting, or keep separate for layers
ggplot() +
  geom_boxplot(data = clean_employer,
               aes(x = group, y = duration_minutes),
               fill = "steelblue", alpha = 0.6) +
  geom_boxplot(data = clean_educator,
               aes(x = group, y = duration_minutes),
               fill = "darkorange", alpha = 0.6) +
  coord_cartesian(ylim = c(0, 80)) +  # Optional: zoom to 0‚Äì60 minutes
  labs(
    title = "Survey Completion Time by Group",
    x = "Respondent Group",
    y = "Duration (minutes)"
  ) +
  theme_minimal()
```

Regarding the proportion of the survey completed, employer responses were more variable‚Äîspanning the full range from partial to full completion. In contrast, educators tended to complete more of the survey, with a concentration near full completion and a less pronounced left tail. The density plot below visualizes these differences in survey progress across groups.

```{r Data_Desc_02, echo=FALSE, fig.align='center'}
#Average percent of survey completed
combined_progress <- bind_rows(
  Employer_Data[-c(1,2), ] %>% mutate(group = "Employer"),
  Educator_Data[-c(1,2), ] %>% mutate(group = "Educator")
) %>%
  mutate(progress = as.numeric(progress))

ggplot(combined_progress, aes(x = progress, fill = group)) +
  geom_density(alpha = 0.4) +
  labs(title = "Survey Progress Density by Group", x = "Progress (%)", y = "Density") +
  theme_minimal()

```

```{r Data_Desc_03, eval=FALSE, fig.align='center'}
#SPACER FOR MORE ANALYTICS
From the educators dataset we could talk about:
* Q27; How long have you been teaching DVM students in the clinical training portion of a DVM program?
* Q28; Does your institution have a teaching hospital?
* Q29; On average, how many dental procedures does your primary care service perform each week?


```

```{r Data_Desc_04, eval=FALSE, fig.align='center'}
#SPACER FOR MORE ANALYTICS

From the employers dataset we could talk about:
* Q33; Which of the following best describes your job setting or organization?
* Q36; On average, how many dental procedures does your practice/oganization/institution perform each week
* Q37; Which of the following best describes the person who completed this survey?
```

## Data Source

Survey data were collected using Qualtrics, a cloud-based experience management platform commonly used for gathering feedback and sentiment across workforce domains. Participants were recruited via email invitation sent by the researcher, using pre-existing contact lists. Participation was voluntary and anonymized.

## Preprocessing Description

Although the employer and educator datasets shared a similar structure, they were not identical. Most preprocessing steps were applied uniformly across both datasets, with minor deviations where needed.

The datasets were imported into the RStudio environment (version 2024.04.1 Build 748). A new variable was created to label the data source ("Educator" or "Employer") for later grouping and visualization. The existing respondent_id column served as a unique identifier and was treated as the primary key.

Initial cleaning involved removing extraneous metadata included by Qualtrics‚Äîsuch as survey start and end times, IP addresses, geolocation data, and question display logic‚Äîall of which were irrelevant to the analysis. These columns were trimmed to streamline the dataset for subsequent transformation and statistical work.

Column names in the original Qualtrics export were alphanumeric but often ambiguous and misleading. Many variable names did not match the corresponding survey question numbers. Our team manually mapped the exported column names to their corresponding survey questions and responses by referencing adjacent metadata fields and using deductive reasoning. This process allowed us to build an index-based column naming structure, which greatly improved the manageability and interpretability of the dataset.

Before diving into question-specific analysis, we first identified the subset of survey questions relevant to our research objectives. All unrelated or out-of-scope items were removed. This step reduced the employer dataset from 176 columns to 100, and the educator dataset from 171 columns to 102.

Several formatting inconsistencies also needed to be resolved. Some multi-select questions appeared in the form of comma-separated text responses within a single column, while others were exported into multiple binary columns. Additionally, for certain questions, a response option that received zero selections was dropped entirely by Qualtrics. To standardize these issues, we implemented a script to ‚Äúexplode‚Äù comma-separated responses into individual binary columns. For dropped columns, we manually reintroduced them as zero-filled dummy variables to preserve the full response structure.

Finally, we filtered out participants who answered less than half of the survey. We also excluded:

-   Employers who responded ‚ÄúNo‚Äù to the question: ‚ÄúDo you work with early career veterinarians (someone who has graduated from a DVM program after May 2021)?‚Äù

-   Educators who responded ‚ÄúNo‚Äù to: ‚ÄúDo you teach in any capacity of the dental curriculum at your institution?‚Äù

After all preprocessing steps, the final cleaned datasets consisted of 13 employer participants and 30 educator participants.

# Statistical Methods

## Research Question Answered

**How do small animal primary care employers (medical directors and practice owners) and primary care veterinary educators differ in regards to their expectations of early career veterinary graduates‚Äô competencies in small animal dentistry?**

## Statistical Questions

***S1.*** Are there significant differences between educators and practice owners in their belief that new graduates are competent in key dental skills on their first day of practice?

***S2.*** Is there a difference between educators and practice owners in their reports (educators‚Äô actual teaching vs. owners‚Äô perceptions) of which dental skills were taught in the pre-clinical DVM curriculum for recent graduates?

***S3.*** Is there a difference between educators and practice owners in their level of agreement about whether specific dental skills should be taught pre-clinically?

***S4.*** Do employers and educators differ in their expectations about how many dental procedures new graduates should complete during clinical training?

***S5.*** Is there difference between the instructional formats in dentistry reported by DVM programs and the formats perceived by employers to have been completed by early career veterinarians?

***S6.*** Do educators and employers differ in their views on which formats of clinical instruction in dentistry should be required for DVM students as part of their clinical training?

***S7.*** Is there a difference between the clinical dentistry skills that educators report DVM students are learning during their clinical training and the skills that employers believe recent graduates have completed as part of their DVM program?

***S8.*** Do educators and employers differ in their opinions about which clinical dentistry skills DVM students should be required to practice or learn during their clinical training?

## Method Description

Statistical questions #1,3, 6, and 8 all deal with participants utilizing a likert scale to answer Strongly Agree, Agree, Disagree, or Strongly Disagree on a variety of skills and procedures. To analyze this data, we will use diverging stacked bar charts and tables for exploratory data analysis and the Mann-Whitney U Test for the formal hypothesis procedure. The Mann-Whitney U Test is a non-parametric test that does not rely on an assumption of normality. It does require independence between datasets and it is reasonable to assume that the educators and employers were independent from each other when taking the survey. The Mann-Whitney test particularly works well with these questions due to the ordinal (and therefore ranked) nature of the data.

Statistical questions #2, 5, and 7 were all questions that asked the participants to ‚Äúselect all that apply‚Äù as it relates to skills in pre-clinical curriculum, format of dental instruction, and skills for clinical training respectively. We will utilize frequency tables and bar plots to explore the data for these questions and use Fisher‚Äôs Exact Test as a formal inference procedure for the comparison of the two groups. Fisher‚Äôs Exact Test works with categorical data with independent samples, in this case educators and employers. In this context, it is preferred over Chi-Squared Tests due to the small sample size and therefore not meeting the expected count threshold that is required to proceed with Chi-Squared Tests. Given the small sample sizes, we acknowledge the limited power of these analyses and may consider post hoc power analyses for these tests.

Statistical question #4 asks participants to enter numerical entries related to the number of dental procedures that should be completed during training in different areas. We plan to produce boxplots and/or histograms to visually examine the data. Depending on the normality or lack thereof of the distributions, we will then conduct either a two-sample t-test or a Mann-Whitney U Test. As mentioned above, the Mann Whitney U test is a non-parametric test that does not depend on the assumption of normality. If the assumption on normality is met, we can consider a two-sample t test for this analysis.

# Results

### S1 Are there significant differences between educators and practice owners in their belief that new graduates are competent in key dental skills on their first day of practice?

### S2 Is there a difference between educators and practice owners in their reports (educators‚Äô actual teaching vs. owners‚Äô perceptions) of which dental skills were taught in the pre-clinical DVM curriculum for recent graduates?

### S3 Is there a difference between educators and practice owners in their level of agreement about whether specific dental skills should be taught pre-clinically?

### S4 Do employers and educators differ in their expectations about how many dental procedures new graduates should complete during clinical training?

### S5 Is there difference between the instructional formats in dentistry reported by DVM programs and the formats perceived by employers to have been completed by early career veterinarians?

### S6 Do educators and employers differ in their views on which formats of clinical instruction in dentistry should be required for DVM students as part of their clinical training?

In question #21 of the employers version of the survey, participants were asked, "Which of the following types of [*clinical instruction in dentistry*]{.underline} do you think that DVM students should be required to complete as part of a [*DVM program*]{.underline}? Select one response for each of the instructional types listed below." The analogue of this question for educators was survey question #17. We want to make a note that the educators survey question had a slight variation in phraseology. It asked, "Which of the following types of [*instruction*]{.underline} do you think DVM students should be required to complete as part of their [*clinical training*]{.underline}? Select one response for each type of instruction listed below.".

This question is targeting how participants feel about what dental veterinarian medical programs are teaching and what topics should be required in their curriculum. The research question asked if there was a difference in opinions on this matter. To infer from the data, we will use the Mann-Whitney U-Test, a non-parametric test also known as Wilcoxin Rank Sign Test. This test assumes mutual exclusivity between groups.

```{r S6, , echo=FALSE, warning=FALSE, fig.align='center'}
educator_cols <- paste0("Q17_", sprintf("%02d", 1:7))
employer_cols  <- paste0("Q21_", sprintf("%02d", 1:7))

# Initialize a results list
mw_results <- list()

# For loop that 
for (i in seq_along(educator_cols)) {
  q_edu <- educator_cols[i]
  q_emp <- employer_cols[i]
  
  # Coerce to numeric
  edu_vals <- as.numeric(Educator_Data_Clean[[q_edu]])
  emp_vals <- as.numeric(Employer_Data_Clean[[q_emp]])
  
  # Remove NAs.  Wilcoxin handles NA values automatically. 
  edu_vals <- edu_vals[!is.na(edu_vals)]
  emp_vals <- emp_vals[!is.na(emp_vals)]
  
  # Only run test if both groups have >1 value
  if (length(edu_vals) > 1 && length(emp_vals) > 1) {
    test_result <- wilcox.test(edu_vals, emp_vals, exact = FALSE)
    
    mw_results[[q_edu]] <- list(
      question = q_edu,
      W = test_result$statistic,
      p_value = test_result$p.value
    )
  } else {
    mw_results[[q_edu]] <- list(
      question = q_edu,
      W = NA,
      p_value = NA
    )
  }
}

# This produces a table of 
mw_df <- do.call(rbind, lapply(mw_results, as.data.frame))
mw_df <- as.data.frame(mw_df)
mw_df$p_value <- as.numeric(mw_df$p_value)
mw_df$question <- rownames(mw_df)
mw_df$significance <- cut(mw_df$p_value,
                          breaks = c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
                          labels = c("***", "**", "*", ".", "ns"))
print(mw_df)
```

```{r TestSpace8, eval=FALSE, echo=FALSE, fig.align='center'}

sapply(Educator_Data_Clean[ , educator_cols[5:7]], function(x) sum(!is.na(as.numeric(x))))
sapply(Employer_Data_Clean[ , employer_cols[5:7]], function(x) sum(!is.na(as.numeric(x))))

Employer_Data_Clean %>% select(starts_with("Q21"))


# Count NAs for reference
sapply(Educator_Data_Clean[ , educator_cols[5:7]], function(x) sum(!is.na(as.numeric(x))))
sapply(Employer_Data_Clean[ , employer_cols[5:7]], function(x) sum(!is.na(as.numeric(x))))

Employer_Data_Clean %>% select(starts_with("Q21"))

# STEP 1: Create combined_mirrored data
combined_mirrored <- bind_rows(
  Educator_Data_Clean %>%
    select(Q17_01, Q17_02, Q17_03) %>%
    pivot_longer(everything(), names_to = "Question", values_to = "Response") %>%
    mutate(
      Group = "Educator",
      Item = case_when(
        Question == "Q17_01" ~ "Didactic",
        Question == "Q17_02" ~ "Simulation",
        Question == "Q17_03" ~ "Wet Lab"
      )
    ),
  
  Employer_Data_Clean %>%
    select(Q21_01, Q21_02, Q21_03) %>%
    pivot_longer(everything(), names_to = "Question", values_to = "Response") %>%
    mutate(
      Group = "Employer",
      Item = case_when(
        Question == "Q21_01" ~ "Didactic",
        Question == "Q21_02" ~ "Simulation",
        Question == "Q21_03" ~ "Wet Lab"
      )
    )
) %>%
  filter(!is.na(Response)) %>%
  mutate(
    Response = factor(Response, levels = 1:4, 
                      labels = c("Strongly Disagree", "Disagree", "Agree", "Strongly Agree")),
    Count = 1,
    Direction = if_else(Group == "Employer", -1, 1)
  ) %>%
  group_by(Group, Item, Response) %>%
  summarise(n = sum(Count) * unique(Direction), .groups = "drop")

# STEP 2: Grouped labels and colors
combined_mirrored <- combined_mirrored %>%
  mutate(
    Response_Grouped = paste(Response, Group, sep = " - "),
    Response = factor(Response, levels = c("Strongly Disagree", "Disagree", "Agree", "Strongly Agree")),
    Response_Grouped = factor(Response_Grouped, levels = c(
      "Strongly Disagree - Educator", "Disagree - Educator", "Agree - Educator", "Strongly Agree - Educator",
      "Strongly Disagree - Employer", "Disagree - Employer", "Agree - Employer", "Strongly Agree - Employer"
    ))
  )

custom_colors <- c(
  "Strongly Disagree - Educator" = "#d73027",
  "Disagree - Educator"          = "#f46d43",
  "Agree - Educator"             = "#fdae61",
  "Strongly Agree - Educator"    = "#fee090",
  "Strongly Disagree - Employer" = "#4575b4",
  "Disagree - Employer"          = "#74add1",
  "Agree - Employer"             = "#abd9e9",
  "Strongly Agree - Employer"    = "#e0f3f8"
)

# STEP 3: Plot
ggplot(combined_mirrored, aes(x = Item, y = n, fill = Response_Grouped)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  scale_y_continuous(labels = abs) +
  scale_fill_manual(values = custom_colors) +
  labs(
    title = "Back-to-Back Comparison of Educator vs Employer Responses",
    x = "Instructional Method",
    y = "Response Count",
    fill = "Likert Response by Group"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")


library(tidyverse)

educator_cols <- paste0("Q17_", sprintf("%02d", 1:7))
employer_cols <- paste0("Q21_", sprintf("%02d", 1:7))

mw_df <- map2_dfr(educator_cols, employer_cols, function(q_edu, q_emp) {
  edu_vals <- as.numeric(Educator_Data_Clean[[q_edu]])
  emp_vals <- as.numeric(Employer_Data_Clean[[q_emp]])

  # Remove NAs
  edu_vals <- edu_vals[!is.na(edu_vals)]
  emp_vals <- emp_vals[!is.na(emp_vals)]

  if (length(edu_vals) > 1 && length(emp_vals) > 1) {
    test_result <- wilcox.test(edu_vals, emp_vals, exact = FALSE)
    tibble(
      question = q_edu,
      W = test_result$statistic,
      p_value = test_result$p.value
    )
  } else {
    tibble(
      question = q_edu,
      W = NA_real_,
      p_value = NA_real_
    )
  }
})

# Add significance stars
mw_df <- mw_df %>%
  mutate(significance = cut(p_value,
                            breaks = c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
                            labels = c("***", "**", "*", ".", "ns")))

print(mw_df)


```

### S7 Is there a difference between the clinical dentistry skills that educators report DVM students are learning during their clinical training and the skills that employers believe recent graduates have completed as part of their DVM program?

### S8 Do educators and employers differ in their opinions about which clinical dentistry skills DVM students should be required to practice or learn during their clinical training?

In question #26 of the employers version of the survey, participants were asked, "Which of the following skills do you think that DVM students should be required to practice/learn as part of the clinical training portion of a DVM program? Select one response for each of the skills listed below." The analogue of this question for educators was survey question #21

This question hits at the sentiment on what both groups think should be required practice/learnings for students. The research question asked if there was a difference in opinions on this matter. To infer from the data, we will use the Mann-Whitney U-Test, a non-parametric test also known as Wilcoxin Rank Sign Test. This test assumes mutual exclusivity between groups.

```{r S8, echo=FALSE, warning=FALSE, fig.align='center'}
educator_cols <- paste0("Q21_", sprintf("%02d", 1:14))
employer_cols  <- paste0("Q26_", sprintf("%02d", 1:14))

# Initialize a results list
mw_results <- list()

# For loop that 
for (i in 1:14) {
  q_edu <- educator_cols[i]
  q_emp <- employer_cols[i]
  
  # Coerce to numeric
  edu_vals <- as.numeric(Educator_Data_Clean[[q_edu]])
  emp_vals <- as.numeric(Employer_Data_Clean[[q_emp]])
  
  # Remove NAs
  edu_vals <- edu_vals[!is.na(edu_vals)]
  emp_vals <- emp_vals[!is.na(emp_vals)]
  
  # Only run test if both groups have >1 value
  if (length(edu_vals) > 1 && length(emp_vals) > 1) {
    test_result <- wilcox.test(edu_vals, emp_vals, exact = FALSE)
    
    mw_results[[q_edu]] <- list(
      question = q_edu,
      W = test_result$statistic,
      p_value = test_result$p.value
    )
  } else {
    mw_results[[q_edu]] <- list(
      question = q_edu,
      W = NA,
      p_value = NA
    )
  }
}


mw_df <- do.call(rbind, lapply(mw_results, as.data.frame))
mw_df <- as.data.frame(mw_df)
mw_df$p_value <- as.numeric(mw_df$p_value)
mw_df$question <- rownames(mw_df)
mw_df$significance <- cut(mw_df$p_value,
                          breaks = c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
                          labels = c("***", "**", "*", ".", "ns"))
print(mw_df)
```

```{r S8v2, fig.align='center'}
view(Educator_Data_Clean %>% select(starts_with("Q17")))
view(Employer_Data_Clean %>% select(starts_with("Q21")))
```

## Findings

## Statistical Analysis

# Discussion/Conclusion

## Interpretation of Results

## Implications of the Study

## Limitations

## Recommendations

## Summary of Key Findings

## Final Thoughts

# Appendix
