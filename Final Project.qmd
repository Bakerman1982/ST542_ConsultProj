---
title: "Bridging the Gap:"
subtitle: "Comparing Employer and Educator Expectations in Small Animal Dentistry"
author: Brock Akerman, Hanan Ali, Taylor Cesarski
date: "June, 25, 2025"
bibliography: references.bib
# csl: apa.csl  # Optional: uncomment and provide a CSL file for citation styling (e.g., APA, MLA)
format:
  pdf:
    pdf-engine: xelatex
    mainfont: "Times New Roman"
    toc: true
    toc-depth: 2
    number-sections: true
    number-figures: true
    fig-caption: true
    number-depth: 2
    fig-align: center
    fig-cap-location: bottom
    fig-pos: 'H'
    geometry: margin=1in
    fontsize: 11pt
    keep-tex: true
    linkcolor: blue

editor_options: 
  chunk_output_type: inline

header-includes:
  - \numberwithin{figure}{section}
---


```{r package_load, warning=FALSE, include=FALSE}
library(ggplot2)
library(tidyverse)
library(janitor)
library(gtools)
library(naniar)
library(patchwork)
library(maps)
library(knitr)

```

```{r Employer Data load, echo=FALSE, message=FALSE, warning=FALSE, results="hide",include=FALSE, error=FALSE}
#############################################
## Connect, Import, group and primary key. ##
#############################################

#Read data into R environment. 
Employer_Data <- read_csv("Employer_Dentistry_Survey.csv") %>% clean_names()
#Name new object to work with leaving original intact/untouched
Employer_Data_Clean <- Employer_Data

#Add grouping identifier now so if we combine data later, we have our groups delineated. 
Employer_Data_Clean <- Employer_Data_Clean %>%
  mutate(
    group = "Employer", #Categorizes all responses as Employer
    respondent_id = row_number() #Maintains respondent ID
  )


############################
#####  DATA WRANGLING  #####
############################

#Adjust headers for readability and add grouping identifier.
#1.) Remove redundancy in column names, 
#2.) Replace "quid" with "Q", and
#3.) All "_text" with "T".
colnames(Employer_Data_Clean) <- gsub("_text$", "_T", gsub("q", "Q", colnames(Employer_Data_Clean)))
#4.) Format the column headers so that it is sort-able both by question and sub question. So where 
#questions are formatted with header Q10_2, the header will now be Q10_02.  This preserves ordering
#and makes indexing easier. 
emp_pad_question_ids <- function(col_names) {
  col_names %>%
    str_replace_all("Q(\\d{1})(?!\\d)", "Q0\\1") %>%
    str_replace_all("Q(\\d{2})_(\\d{1})(?!\\d)", "Q\\1_0\\2")}

#Apply above formatting changes to data frame column names
colnames(Employer_Data_Clean) <- emp_pad_question_ids(colnames(Employer_Data_Clean))

#Removes Qualtric metadata from the first two rows
Employer_Data_Clean <- Employer_Data_Clean %>% slice(-1, -2)



### QUESTION-BY-QUESTION Cleaning

#------------
#Question #04
#------------
#Renames the text response to index 13 and places it in its order. 
Employer_Data_Clean <- Employer_Data_Clean %>%
  rename(Q04_13 = Q04_12_T)

#------------
#Question #09 does not need correcting. 
#------------

#------------
#Question #16
#------------
#Renames the text response to index 11 and places it in its order. 
Employer_Data_Clean <- Employer_Data_Clean %>%
  rename(Q16_11 = Q16_10_T) 

#Process Q12: Split responses and pivot to wide format
Employer_Data_Clean <- Employer_Data_Clean %>%
  mutate(respondent_id = row_number()) %>%
  separate_rows(Q16, sep = ",") %>%
  mutate(Q16 = str_trim(Q16)) %>%
  #filter(!is.na(Q16)) %>%  # üîß prevent Q16_NA column in pivot_wider
  mutate(Q16 = str_pad(Q16, width = 2, pad = "0"),
         value = 1) %>%
  pivot_wider(
    names_from = Q16,
    names_prefix = "Q16_",
    values_from = value,
    values_fill = 0
  ) %>%
  right_join(select(Employer_Data_Clean, respondent_id), by = "respondent_id")  # üîÅ bring back NA responders


if (!"Q16_09" %in% colnames(Employer_Data_Clean)) {
  Employer_Data_Clean$Q16_09 <- 0
}


#------------
#Question #17
#------------
#Renames the text response to index 14 and places it in its order.
Employer_Data_Clean <- Employer_Data_Clean %>%
  rename(Q17_15 = Q17_14_T)

#------------
#Question #20
#------------
# Create binary indicator columns from Q16.  Recall that Q16 was a multiple responsive
# "Select all that Apply" question where participants could choose however many they 
# wanted.  In the Qualtrics output, these responses were comma-separated.  This query
# breaks each reponse out over a column and assigns values of "0" or "1" depending on 
# whether they choose that particular response. The same issue is address in Question #20. 
Q20_binary <- Employer_Data_Clean %>%
  select(respondent_id, Q20) %>%
  separate_rows(Q20, sep = ",") %>%
  mutate(Q20 = str_trim(Q20)) %>%
  #filter(!is.na(Q20)) %>%   # üëà Prevents Q20_NA from being created
  mutate(Q20 = str_pad(Q20, width = 2, pad = "0"),
         value = 1) %>%
  pivot_wider(
    names_from = Q20,
    names_prefix = "Q20_",
    values_from = value,
    values_fill = 0
  ) %>%
  right_join(select(Employer_Data_Clean, respondent_id), by = "respondent_id")

# Remove the old Q16 columns and join the binary ones on respondent_id
Employer_Data_Clean <- Employer_Data_Clean %>%
  select(-Q20) %>%
  left_join(Q20_binary, by = "respondent_id")

# Renames the text response to index 07 and places it in its order.
Employer_Data_Clean <- Employer_Data_Clean %>%
  rename(Q20_07 = Q20_06_T) %>%
  relocate(Q20_07, .after = Q20_06)

# Add Q16_05 as a column of zeros if it doesn't exist (it does not)
if (!"Q20_05" %in% colnames(Employer_Data_Clean)) {
  Employer_Data_Clean$Q20_05 <- 0
}

#------------
#Question #21
#------------
#Renames the text response to index 07 and places it in its order.
Employer_Data_Clean <- Employer_Data_Clean %>%
  rename(Q21_07 = Q21_06_T) 

#------------
#Question #22 does not need correcting. 
#------------

#------------
#Question #24 does not need correcting. 
#------------

#------------
#Question #25
#------------
# Create binary indicator columns from Q25.  Recall that Q25 was a multiple responsive
# "Select all that Apply" question where participants could choose however many they 
# wanted.  In the Qualtrics output, these responses were comma-separated.  This query
# breaks each reponse out over a column and assigns values of "0" or "1" depending on 
# whether they choose that particular response. The same issue is address in Question #16. 
Q25_binary <- Employer_Data_Clean %>%
  select(respondent_id, Q25) %>%
  separate_rows(Q25, sep = ",") %>%
  mutate(Q25 = str_trim(Q25)) %>%
  #filter(!is.na(Q25)) %>%   # üëà Prevents Q25_NA
  mutate(Q25 = str_pad(Q25, width = 2, pad = "0"),
         value = 1) %>%
  pivot_wider(
    names_from = Q25,
    names_prefix = "Q25_",
    values_from = value,
    values_fill = 0
  ) %>%
  right_join(select(Employer_Data_Clean, respondent_id), by = "respondent_id")


# Remove the old Q16 columns and join the binary ones in
Employer_Data_Clean <- Employer_Data_Clean %>%
  select(-Q25) %>%
  left_join(Q25_binary, by = "respondent_id")

# Add Q25_13 as a column of zeros if it doesn't exist (it does not)
if (!"Q25_13" %in% colnames(Employer_Data_Clean)) {
  Employer_Data_Clean$Q25_13 <- 0
}

# Rename and relocate the "Other" text entry for Q16
Employer_Data_Clean <- Employer_Data_Clean %>%
  rename(Q25_14 = Q25_13_T) %>%
  relocate(Q25_14, .after = Q25_13)

#------------
#Question #26
#------------
#Renames the text response to index 14 and places it in its order. 
Employer_Data_Clean <- Employer_Data_Clean %>%
  rename(Q26_14 = Q26_13_T) 


##########################
##### FILTER DATASET #####
##########################
#"Q20_NA"
#"Q25_NA"


#Remove irrelevant/problematic columns to the research/stats questions
Employer_Data_Clean <- Employer_Data_Clean %>%
  mutate(progress = as.numeric(progress)) %>%
  filter(Q02 == '1', progress >= 50) %>%
  select(
    ip_address, progress, duration_in_seconds,
    finished, recorded_date, response_id, group, respondent_id,
    starts_with("Q04"),
    starts_with("Q09"),
    starts_with("Q16"),
    starts_with("Q17"),
    starts_with("Q20"),
    starts_with("Q21"),
    starts_with("Q22"),
    starts_with("Q24"),
    starts_with("Q25"),
    starts_with("Q26"),
    -Q16_NA,  # üëà drop this
    -Q20_NA,  # üëà drop this
    -Q25_NA
  )

#Identify metadata columns to keep at the front
emp_meta_cols <- c("ip_address", "progress", "duration_in_seconds",
               "finished", "recorded_date", "response_id", "group", "respondent_id")

#Identify and sort Q columns using mixedsort
emp_q_cols <- setdiff(colnames(Employer_Data_Clean), emp_meta_cols)
emp_q_cols_sorted <- mixedsort(emp_q_cols)

#Reorder the data frame
Employer_Data_Clean <- Employer_Data_Clean[, c(emp_meta_cols, emp_q_cols_sorted)]
```

```{r Educator Data load, echo=FALSE, message=FALSE, warning=FALSE, results="hide",include=FALSE, error=FALSE}
#############################################
## Connect, Import, group and primary key. ##
#############################################

#Read data into R environment. 
Educator_Data <- read_csv("PCVE_Dentistry_Survey.csv") %>% clean_names()
#Name new object to work with leaving original intact/untouched
Educator_Data_Clean <- Educator_Data

#Add identifier affirming educator responses. 
Educator_Data_Clean <- Educator_Data_Clean %>%
  mutate(
    group = "Educator",
    respondent_id = row_number()
  )

############################
#####  DATA WRANGLING  #####
############################

#Adjust headers for readability and add grouping identifier.
  #1.) Remove redundancy in column names, 
  #2.) Replace "quid" with "Q", and
  #3.) All "_text" with "T".
colnames(Educator_Data_Clean) <- gsub("_text$", "_T", gsub("q", "Q", colnames(Educator_Data_Clean)))
  #4.) Format the column headers so that it is sort-able both by question and sub question. So where 
    #questions are formatted with header Q10_2, the header will now be Q10_02.  This preserves ordering
    #and makes indexing easier. 
edu_pad_question_ids <- function(col_names) {
  col_names %>%
    str_replace_all("Q(\\d{1})(?!\\d)", "Q0\\1") %>%
    str_replace_all("Q(\\d{2})_(\\d{1})(?!\\d)", "Q\\1_0\\2")}

#Apply above formatting changes to data frame column names
colnames(Educator_Data_Clean) <- edu_pad_question_ids(colnames(Educator_Data_Clean))

#Removes Qualtric metadata from the first two rows
Educator_Data_Clean <- Educator_Data_Clean %>% slice(-1, -2)


### QUESTION-BY-QUESTION Cleaning

#------------
#Question #04
#------------
#Renames the text response to index 13 and places it in its order. 
Educator_Data_Clean <- Educator_Data_Clean %>%
  rename(Q04_13 = Q04_12_T)

#------------
#Question #07 does not need correcting. 
#------------

#------------
#Question #12
#------------
  #Renames the text response to index 11 and places it in its order. 
Educator_Data_Clean <- Educator_Data_Clean %>%
  rename(Q12_11 = Q12_10_T) 

  #Process Q12: Split responses and pivot to wide format
Educator_Data_Clean <- Educator_Data_Clean %>%
  # Create a temporary respondent ID if not already done
  mutate(respondent_id = row_number()) %>%
  # Separate comma-separated values into long format
  separate_rows(Q12, sep = ",") %>%
  # Trim whitespace if any
  mutate(Q12 = str_trim(Q12)) %>%
  # Pad values with leading zero for consistent column naming (01, 02, ..., 11)
  mutate(Q12 = str_pad(Q12, width = 2, pad = "0"),
         value = 1) %>%
  # Pivot wider to get binary indicator columns
  pivot_wider(
    names_from = Q12,
    names_prefix = "Q12_",
    values_from = value,
    values_fill = 0
  )

#------------
#Question #13
#------------
#Renames the text response to index 14 and places it in its order.
Educator_Data_Clean <- Educator_Data_Clean %>%
  rename(Q13_14 = Q13_13_T)

#------------
#Question #16
#------------
# Create binary indicator columns from Q16.  Recall that Q16 was a multiple responsive
# "Select all that Apply" question where participants could choose however many they 
# wanted.  In the Qualtrics output, these responses were comma-separated.  This query
# breaks each reponse out over a column and assigns values of "0" or "1" depending on 
# whether they choose that particular response. The same issue is address in Question #20. 
Q16_binary <- Educator_Data_Clean %>%
  select(respondent_id, Q16) %>%
  separate_rows(Q16, sep = ",") %>%
  mutate(Q16 = str_trim(Q16)) %>%
  mutate(Q16 = str_pad(Q16, width = 2, pad = "0"),
         value = 1) %>%
  pivot_wider(
    names_from = Q16,
    names_prefix = "Q16_",
    values_from = value,
    values_fill = 0
  )

  # Remove the old Q16 columns and join the binary ones on respondent_id
Educator_Data_Clean <- Educator_Data_Clean %>%
  select(-Q16) %>%
  left_join(Q16_binary, by = "respondent_id")

  # Renames the text response to index 07 and places it in its order.
Educator_Data_Clean <- Educator_Data_Clean %>%
  rename(Q16_07 = Q16_06_T) %>%
  relocate(Q16_07, .after = Q16_06)

  # Add Q16_05 as a column of zeros if it doesn't exist (it does not)
if (!"Q16_05" %in% colnames(Educator_Data_Clean)) {
  Educator_Data_Clean$Q16_05 <- 0
}

#------------
#Question #17
#------------
#Renames the text response to index 07 and places it in its order.
Educator_Data_Clean <- Educator_Data_Clean %>%
  rename(Q17_07 = Q17_06_T) 

#------------
#Question #18 does not need correcting. 
#------------

#------------
#Question #19 does not need correcting. 
#------------

#------------
#Question #20
#------------
# Create binary indicator columns from Q16.  Recall that Q16 was a multiple responsive
# "Select all that Apply" question where participants could choose however many they 
# wanted.  In the Qualtrics output, these responses were comma-separated.  This query
# breaks each reponse out over a column and assigns values of "0" or "1" depending on 
# whether they choose that particular response. The same issue is address in Question #16. 
Q20_binary <- Educator_Data_Clean %>%
  select(respondent_id, Q20) %>%
  separate_rows(Q20, sep = ",") %>%
  mutate(Q20 = str_trim(Q20)) %>%
  mutate(Q20 = str_pad(Q20, width = 2, pad = "0"),
         value = 1) %>%
  pivot_wider(
    names_from = Q20,
    names_prefix = "Q20_",
    values_from = value,
    values_fill = 0
  )

# Remove the old Q16 columns and join the binary ones in
Educator_Data_Clean <- Educator_Data_Clean %>%
  select(-Q20) %>%
  left_join(Q20_binary, by = "respondent_id")

# Rename and relocate the "Other" text entry for Q16
Educator_Data_Clean <- Educator_Data_Clean %>%
  rename(Q20_14 = Q20_13_T) %>%
  relocate(Q20_14, .after = Q20_13)

#------------
#Question #21
#------------
#Renames the text response to index 14 and places it in its order. 
Educator_Data_Clean <- Educator_Data_Clean %>%
  rename(Q21_14 = Q21_13_T) 


##########################
##### FILTER DATASET #####
##########################

#Remove irrelevant/problematic columns to the research/stats questions
Educator_Data_Clean <- Educator_Data_Clean %>%
  mutate(progress = as.numeric(progress)) %>%
  filter(Q44 != "2", progress >= 50, !(response_id %in% c('R_1By20if00mw1SfP', 'R_7kFWGHJpi0UkB7X', 'R_5LXUELTJZBjMt84','R_4CdkBhi7XaGfwNb','R_8EYfypBzjIWzwn7')) ) %>%
  select(
    ip_address, progress, duration_in_seconds,
    finished, recorded_date, response_id, group, respondent_id,
    starts_with("Q04"),
    starts_with("Q07"),
    starts_with("Q12"),
    starts_with("Q13"),
    starts_with("Q16"),
    starts_with("Q17"),
    starts_with("Q18"),
    starts_with("Q19"),
    starts_with("Q20"),
    starts_with("Q21")
  )

#Identify metadata columns to keep at the front
edu_meta_cols <- c("ip_address", "progress", "duration_in_seconds",
               "finished", "recorded_date", "response_id", "group", "respondent_id")

#Identify and sort Q columns using mixedsort
edu_q_cols <- setdiff(colnames(Educator_Data_Clean), edu_meta_cols)
edu_q_cols_sorted <- mixedsort(edu_q_cols)

#Reorder the data frame
Educator_Data_Clean <- Educator_Data_Clean[, c(edu_meta_cols, edu_q_cols_sorted)]
```

# Abstract

Authors of each section

Introduction - Taylor Cesarski
Data - Brock Akerman
Methods - Taylor Cesarski
Results - All

* Questions 1-4 -  Hanan Ali
* Questions 5,7 - Taylor Cesarski
* Questions 6,8 - Brock Akerman

# Introduction

Dr. Mariea Ross-Estrada, a faculty member at North Carolina State University's College of Veterinary Medicine, is exploring whether there are differences between the expectations of small animal primary care veterinary employers and veterinary educators regarding new graduates' competencies in dentistry. Through her own professional experience and conversations with colleagues, Dr. Ross-Estrada observed that many veterinarians must rely on on-the-job training to gain the skills necessary in small animal dentistry. These shared experiences prompted her to investigate whether there is a misalignment in what is taught in veterinary programs and what is expected in clinical practice.

To explore this question, Dr. Ross-Estrada distributed two surveys: one to medical directors and private practice owners and the other to primary care veterinary educators. Both surveys included similar questions regarding what early-career veterinarians are expected to have learned during their education and the skills they are expected to perform in practice.

## Research Question

How do small animal primary care employers (medical directors and practice owners) and primary care veterinary educators differ in regards to their expectations of early career veterinary graduates‚Äô competencies in small animal dentistry?

## Statistical Questions

1.  Are there significant differences between educators and practice owners in their belief that new graduates are competent in key dental skills on their first day of practice?

2.  Is there a difference between educators and practice owners in their reports (educators‚Äô actual teaching vs. owners‚Äô perceptions) of which dental skills were taught in the pre-clinical DVM curriculum for recent graduates?

3.  Is there a difference between educators and practice owners in their level of agreement about whether specific dental skills should be taught pre-clinically?

4.  Do employers and educators differ in their expectations about how many dental procedures new graduates should complete during clinical training?

5.  Is there difference between the instructional formats in dentistry reported by DVM programs and the formats perceived by employers to have been completed by early career veterinarians?

6.  Do educators and employers differ in their views on which formats of clinical instruction in dentistry should be required for DVM students as part of their clinical training?

7.  Is there a difference between the clinical dentistry skills that educators report DVM students are learning during their clinical training and the skills that employers believe recent graduates have completed as part of their DVM program?

8.  Do educators and employers differ in their opinions about which clinical dentistry skills DVM students should be required to practice or learn during their clinical training?

# Data

## Data Description

Two separate surveys were administered to mutually exclusive groups: veterinary employers who have worked with students, and educators who have taught students. There was no overlap between these groups and they can be assumed to be independent.

The employer data set consists of responses from 29 participants answering 40 questions, while the educator data set includes 43 participants answering 34 questions. Each group was asked a single qualifying question to determine eligibility for participation, along with nine questions covering demographics and institutional context. Educators were then presented with 24 competency and sentiment-based questions, while employers answered 30 such items focused on professional expectations and training in veterinary medicine.

Survey questions took several forms. Some were binary (Yes/No), particularly those related to demographics and institutional affiliation. Others used a "select all that apply" format, commonly seen in questions asking respondents to identify procedures performed at their practice. Many of these questions were followed by Likert-scale items. The Likert scales were even-numbered and omitted a neutral option, which may have contributed to at least two instances where respondents selected both ‚Äúagree‚Äù and ‚Äúdisagree‚Äù for the same item.

Several questions offered an ‚ÄúOther‚Äù response with a text box for elaboration. A few required numeric input, such as estimates of hours worked or the number of practicing veterinarians. These integer fields were not restricted by any upper bound, regardless of contextual reasonableness.

#### Global survey session metrics

```{r}
#| label: Data_Desc_01
#| fig-cap: "Assessing survey elapsed time distribution via box plots to understand engagement by survey group."
#| echo: false
#| fig-align: center

#Average time for survey completion
# Convert and clean both datasets
clean_employer <- Employer_Data[-c(1,2), ] %>%
  mutate(
    duration_in_seconds = as.numeric(duration_in_seconds),
    duration_minutes = duration_in_seconds / 60,
    group = "Employer"
  )

clean_educator <- Educator_Data[-c(1,2), ] %>%
  mutate(
    duration_in_seconds = as.numeric(duration_in_seconds),
    duration_minutes = duration_in_seconds / 60,
    group = "Educator"
  )

# Combine for optional single-geom plotting, or keep separate for layers
ggplot() +
  geom_boxplot(data = clean_employer,
               aes(x = group, y = duration_minutes),
               fill = "steelblue", alpha = 0.6) +
  geom_boxplot(data = clean_educator,
               aes(x = group, y = duration_minutes),
               fill = "darkorange", alpha = 0.6) +
  coord_cartesian(ylim = c(0, 80)) +  # Optional: zoom to 0‚Äì60 minutes
  labs(
    title = "Survey Completion Time by Group",
    x = "Respondent Group",
    y = "Duration (minutes)"
  ) +
  theme_minimal()
```

Survey completion time differed by group. Educators, on average, spent more time completing the survey than employers. While no follow-up question asked participants to explain their response time, this discrepancy may reflect greater engagement or a tendency for more elaborated responses among educators. It may also suggest a greater willingness among educators to participate more thoughtfully. The box plot below illustrates the distribution of survey duration (in minutes) by group.

```{r}
#| label: Data_Desc_02
#| fig-cap: "Assessing survey completion as a density curve to understand engagement by survey group."
#| echo: false
#| fig-align: center

#Average percent of survey completed
combined_progress <- bind_rows(
  Employer_Data[-c(1,2), ] %>% mutate(group = "Employer"),
  Educator_Data[-c(1,2), ] %>% mutate(group = "Educator")
) %>%
  mutate(progress = as.numeric(progress))

ggplot(combined_progress, aes(x = progress, fill = group)) +
  geom_density(alpha = 0.4) +
  labs(title = "Survey Progress Density by Group", x = "Progress (%)", y = "Density") +
  theme_minimal()

```

Regarding the proportion of the survey completed, employer responses were more variable‚Äîspanning the full range from partial to full completion. In contrast, educators tended to complete more of the survey, with a concentration near full completion and a less pronounced left tail. The density plot below visualizes these differences in survey progress across groups.

```{r}
#| label: Data_Desc_03
#| fig-cap: "Geographic distribution of survey respondents across the United States."
#| echo: false
#| fig-align: center

# Clean Employer Data
Employer_Clean <- Employer_Data %>%
  slice(-c(1,2)) %>%
  mutate(
    latitude = as.numeric(location_latitude),
    longitude = as.numeric(location_longitude)
  ) %>%
  filter(!is.na(latitude) & !is.na(longitude)) %>%
  mutate(group = "Employer")

# Clean Educator Data
Educator_Clean <- Educator_Data %>%
  slice(-c(1,2)) %>%
  mutate(
    latitude = as.numeric(location_latitude),
    longitude = as.numeric(location_longitude)
  ) %>%
  filter(!is.na(latitude) & !is.na(longitude)) %>%
  filter(
    between(latitude, 24, 50),
    between(longitude, -125, -65)
  ) %>%
  mutate(group = "Educator")

# Combine datasets
All_Locations <- bind_rows(Employer_Clean, Educator_Clean)

# Remove the specific outliers
All_Locations <- All_Locations %>%
  filter(!(
    (abs(latitude - 43.5204) < 1e-6 & abs(longitude + 80.2245) < 1e-6) |  
    (abs(latitude - 35.6339) < 1e-6 & abs(longitude - 140.0391) < 1e-6) | 
    (abs(latitude + 5.2521) < 1e-6 & abs(longitude - 39.7633) < 1e-6)     
  ))

# Get US map data
us_map <- map_data("state")

# Plot
ggplot() +
  geom_polygon(data = us_map, aes(x = long, y = lat, group = group), 
               fill = "gray90", color = "white") +
  geom_point(data = All_Locations, aes(x = longitude, y = latitude, color = group), 
             size = 2, alpha = 0.7) +
  coord_fixed(1.3) +
  theme_minimal() +
  theme(
    panel.grid = element_blank(),
    axis.title = element_blank(),
    axis.text = element_blank(),
    axis.ticks = element_blank(),
    plot.title = element_text(hjust = 0.5)
  ) +
  labs(title = "Geographic Distribution of Survey Respondents",
       color = "Group")
```

Since our analysis focused on the representativeness of the United States, we identified three sets of coordinates in the educator dataset corresponding to international institutions: the University of Guelph in Ontario, Canada; Zanzibar University in Chake, Tanzania; and Chiba University in Chiba, Japan. Employer survey participants were predominantly sampled from locations along the eastern seaboard of the United States, while educators were more widely distributed across the country. We highlight this to illustrate that perceptions of veterinary dental students‚Äîparticularly among employers‚Äîmay differ for individuals located far from the regions where most participants were sampled. Additionally, because many of the responses came from major metropolitan areas, our findings may underrepresent opinions regarding student knowledge gaps in more rural settings.

#### Educator metrics

```{r}
#| label: Data_Desc_04
#| fig-cap: "Educator contextualized background information about teaching and procedures."
#| echo: false
#| fig-align: center

# Remove metadata rows
Educator_Data_DESC03 <- Educator_Data[-c(1, 2), ]

# Ensure q27 is numeric and remove NA values
Educator_Data_DESC03$q27 <- as.numeric(Educator_Data_DESC03$q27)
Educator_Data_DESC03 <- Educator_Data_DESC03 %>% filter(!is.na(q27))

# Ensure q41_1 is numeric and remove NA values
Educator_Data_DESC03$q41_1 <- as.numeric(Educator_Data_DESC03$q41_1)
Educator_Data_DESC03 <- Educator_Data_DESC03 %>% filter(!is.na(q41_1) | !is.na(q27))

# Create ceiling-binned versions
Educator_Data_DESC03 <- Educator_Data_DESC03 %>%
  mutate(
    q27_binned = ceiling(q27),
    q41_1_binned = ceiling(q41_1)
  )

# Compute max y values for neat y-axis limits
max_count_p1 <- Educator_Data_DESC03 %>%
  count(q27_binned) %>%
  pull(n) %>%
  max(na.rm = TRUE)

max_count_p2 <- Educator_Data_DESC03 %>%
  count(q41_1_binned) %>%
  pull(n) %>%
  max(na.rm = TRUE)

# Plot 1: Years Teaching (with ceiling bins and clean y-axis)
p1 <- ggplot(Educator_Data_DESC03, aes(x = q27_binned)) +
  geom_bar(
    fill = "#4C72B0",
    color = "white"
  ) +
  scale_x_continuous(
    breaks = seq(0, max(Educator_Data_DESC03$q27_binned, na.rm = TRUE), by = 1)
  ) +
  scale_y_continuous(
    breaks = seq(0, max(max_count_p1 + 2, 2), by = 2)
  ) +
  labs(
    title = "Years Teaching DVM Students",
    x = "Years Teaching (Rounded Up)",
    y = "Number of Respondents"
  ) +
  theme_minimal() +
  theme(
    panel.grid.major = element_line(color = "grey85", linetype = "dashed"),
    panel.grid.minor = element_blank(),
    plot.title = element_text(face = "bold", size = 12),
    axis.title = element_text(size = 10)
  )

# Plot 2: Procedures per Week (with ceiling bins and clean y-axis)
p2 <- ggplot(Educator_Data_DESC03, aes(x = q41_1_binned)) +
  geom_bar(
    fill = "#DD8452",
    color = "white"
  ) +
  scale_x_continuous(
    breaks = seq(0, max(Educator_Data_DESC03$q41_1_binned, na.rm = TRUE), by = 1)
  ) +
  scale_y_continuous(
    breaks = seq(0, max(max_count_p2 + 2, 2), by = 2)
  ) +
  labs(
    title = "Dental Procedures per Week",
    x = "Procedures per Week (Rounded Up)",
    y = "Number of Educators"
  ) +
  theme_minimal() +
  theme(
    panel.grid.major = element_line(color = "grey85", linetype = "dashed"),
    panel.grid.minor = element_blank(),
    plot.title = element_text(face = "bold", size = 12),
    axis.title = element_text(size = 10)
  )

# Combine plots side by side
p1 + p2 + plot_layout(widths = c(1, 1))
```

Figure 3.3 provides an overview of the survey participants and their institutions. Most respondents reported having between 2 and 4 years of experience teaching veterinary students in clinical training. The distribution of years taught appears approximately normal, with fewer educators at the lower and upper ends of the experience range. Respondents also reported the number of dental procedures performed by their primary care service each week. While some outliers from busier institutions reported higher volumes, most educators estimated performing between 1 and 8 procedures per week.

#### Employer metrics

The employer dataset was considerably smaller than the educator dataset, which may reflect differences in motivation or willingness to complete the survey. Most employer respondents identified as practice owners, and approximately 75% indicated they were employed in private practice. This aligns with findings from the American Veterinary Medical Association (AVMA), which reported that "most veterinarians age 75 or younger, 83.9%, work in private clinical practice" [@avma2019].

```{r}
#| label: Data_Desc_06
#| fig-cap: ""
#| echo: false
#| warning: false
#| fig-align: center

#* Q33; Which of the following best describes your job setting or organization?
# Mapping vector
q33_labels <- c(
  "1" = "Independently owned single veterinary practice",
  "2" = "Independently owned group veterinary practice",
  "3" = "Group corporate veterinary practice",
  "4" = "Institution (e.g., aquarium, shelter, zoo, etc.)",
  "5" = "Industry/commercial",
  "6" = "Government (local, state, federal)",
  "7" = "Uniformed services",
  "8" = "Other"
)

# Clean and map responses, remove first two metadata rows
q33_clean <- Employer_Data[["q33"]] %>%
  .[-c(1,2)] %>%                          # Remove first two metadata rows
  na.omit() %>%
  as.character() %>%
  recode(!!!q33_labels)

# Create counts and percentages
q33_table <- as.data.frame(table(q33_clean)) %>%
  rename(`Job Setting` = q33_clean, `Count` = Freq) %>%
  mutate(Percentage = round(Count / sum(Count) * 100, 1))

# Pretty table
kable(q33_table, caption = "Job Setting or Organization: Counts and Percentages", align = "lrr", booktabs = TRUE)


#* Q37; Which of the following best describes the person who completed this survey?
# Mapping vector for Q37
q37_labels <- c(
  "1" = "Practice owner",
  "2" = "Practice manager/HR representative",
  "3" = "Associate veterinarian",
  "4" = "Other"
)

# Clean and map responses for Q37
q37_clean <- Employer_Data[["q37"]] %>%
  .[-c(1,2)] %>%             # Remove metadata rows
  na.omit() %>%
  as.character() %>%
  recode(!!!q37_labels)

# Create counts and percentages for Q37
q37_table <- as.data.frame(table(q37_clean)) %>%
  rename(`Respondent Role` = q37_clean, `Count` = Freq) %>%
  mutate(Percentage = round(Count / sum(Count) * 100, 1))

# Display table for Q37
kable(q37_table, caption = "Respondent Role: Counts and Percentages", align = "lrr", booktabs = TRUE)


```

Survey responses were also heavily skewed toward practice ownership, with 63.6% of employer participants identifying as owners. By comparison, the same AVMA survey reported that only 21.3% of veterinarians identified as practice owners. This discrepancy may be due to the smaller sample size or the possibility that practice owners were more willing to complete the survey than associates or other veterinary professionals.


```{r}
#| label: Data_Desc_07
#| fig-cap: "Average dental procedures employer survey participants indicated they performed each week."
#| echo: false
#| warning: false
#| fig-align: center
#* Q36; On average, how many dental procedures does your practice/oganization/institution perform each week


# Clean and prepare data
Employer_Clean <- Employer_Data %>%
  slice(-c(1,2)) %>%                       # remove metadata rows
  mutate(q36_1 = as.numeric(q36_1)) %>%
  filter(!is.na(q36_1)) %>%
  mutate(q36_1_binned = ceiling(q36_1))   # binning like p2

# Calculate max count for y-axis scaling
max_count_p36_1 <- Employer_Clean %>%
  count(q36_1_binned) %>%
  pull(n) %>%
  max(na.rm = TRUE)

# Plot similar to p2
p_q36_1 <- ggplot(Employer_Clean, aes(x = q36_1_binned)) +
  geom_bar(
    fill = "#DD8452",
    color = "white"
  ) +
  scale_x_continuous(
    breaks = seq(0, max(Employer_Clean$q36_1_binned, na.rm = TRUE), by = 1)
  ) +
  scale_y_continuous(
    breaks = seq(0, max(max_count_p36_1 + 2, 2), by = 2)
  ) +
  labs(
    title = "Individual Dental Procedures per Week",
    x = "Procedures per Week (Rounded Up)",
    y = "Number of Respondents"
  ) +
  theme_minimal() +
  theme(
    panel.grid.major = element_line(color = "grey85", linetype = "dashed"),
    panel.grid.minor = element_blank(),
    plot.title = element_text(face = "bold", size = 12),
    axis.title = element_text(size = 10)
  )

p_q36_1
```

Figure 3.5 shows that procedure counts tend to be lower in the employer group compared to the educator group, although the overall distribution shapes are similar. In both groups, the data exhibit a right-skewed pattern, with most respondents reporting lower procedure counts and a few outliers representing higher volumes. This pattern aligns with the intuitive understanding that while some practices or institutions have greater clinical demands on veterinarians, these cases are less common‚Äîat least based on the survey responses.

## Data Source

Survey data were collected using Qualtrics, a cloud-based experience management platform commonly used for gathering feedback and sentiment across workforce domains. Participants from the educator survey were recruited via email invitation sent by the researcher, using pre-existing contact lists. Dr. Ross-Estrada distributed the employer survey to her personal and professional networks online. Participation was voluntary and anonymous. There was no incentive offered for completing the survey.

## Preprocessing Description

Although the employer and educator data sets shared a similar structure, they were not identical. Most pre-processing steps were applied uniformly across both data sets, with minor deviations where needed.

The data sets were imported into the RStudio environment (version 2024.04.1 Build 748). A new variable was created to label the data source ("Educator" or "Employer") for later grouping and visualization. The existing respondent_id column served as a unique identifier and was treated as the primary key.

Initial cleaning involved removing extraneous metadata included by Qualtrics‚Äîsuch as survey start and end times, IP addresses, geolocation data, and question display logic‚Äîall of which were irrelevant to the analysis. These columns were trimmed to streamline the dataset for subsequent transformation and statistical work.

Column names in the original Qualtrics export were alphanumeric but often ambiguous and misleading. Many variable names did not match the corresponding survey question numbers. Our team manually mapped the exported column names to their corresponding survey questions and responses by referencing adjacent metadata fields and using deductive reasoning. This process allowed us to build an index-based column naming structure, which greatly improved the manageability and interpretability of the dataset.

Before diving into question-specific analysis, we first identified the subset of survey questions relevant to our research objectives. All unrelated or out-of-scope items were removed. This step reduced the employer dataset from 176 columns to 100, and the educator dataset from 171 columns to 102.

Several formatting inconsistencies also needed to be resolved. Some multi-select questions appeared in the form of comma-separated text responses within a single column, while others were exported into multiple binary columns. Additionally, for certain questions, a response option that received zero selections was dropped entirely by Qualtrics. To standardize these issues, we implemented a script to ‚Äúexplode‚Äù comma-separated responses into individual binary columns. For dropped columns, we manually reintroduced them as zero-filled dummy variables to preserve the full response structure.

Finally, we filtered out participants who answered less than half of the survey. We also excluded:

-   Employers who responded ‚ÄúNo‚Äù to the question: ‚ÄúDo you work with early career veterinarians (someone who has graduated from a DVM program after May 2021)?‚Äù

-   Educators who responded ‚ÄúNo‚Äù to: ‚ÄúDo you teach in any capacity of the dental curriculum at your institution?‚Äù

After all preprocessing steps, the final cleaned datasets consisted of 13 employer participants and 30 educator participants.

# Statistical Methods

## Method Description

#### Likert scale questions (statistical questions #1,3, 6, and 8)

These questions use a Likert scale with response options: Strongly Agree, Agree, Disagree, and Strongly Disagree across a variety of skills and procedures. Given the ordinal nature of these responses, we will use diverging stacked bar charts and summary tables to visually explore the data, followed by a Mann-Whitney U Test for formal hypothesis testing.

The Mann-Whitney U Test is a non-parametric test used to assess whether there is a statistically significant difference in the distributions of ordinal or continuous variables between two independent groups. In this case, educators and employers are assumed to be independent, consistent with the survey design.

This test is appropriate for Likert-scale data because:

* It does not assume normality (unlike the t-test),
* It respects the ordinal (ranked) structure of the data,
* It retains statistical power in small samples.

```{r}
#| label: mannwhitneytable
#| echo: false
#| warning: false
#| fig-cap: " "
#| fig-align: center

# Create a visual summary table
mw_data <- data.frame(
  Group = c("Group 1 (e.g., Educators)", "Group 2 (e.g., Employers)"),
  `Sample Size` = c("n‚ÇÅ", "n‚ÇÇ"),
  `Sum of Ranks` = c("R‚ÇÅ", "R‚ÇÇ"),
  `Mean Rank` = c("R‚ÇÅ / n‚ÇÅ", "R‚ÇÇ / n‚ÇÇ")
)

kable(mw_data, align = "lrrr", caption = "Mann-Whitney U Rank Summary Table", booktabs = TRUE)

```

In order to calculate the test statistic and p-value for a Mann-Whitney U Test:

* All observations are ranked together
* The sum of the ranks for each group is calculated ($R_1$ and $R_2$)
* The test statistic U is then calculated as the minimum of $U_1$ and $U_2$ where $U_1$ and $U_2$ are the following: $U_1 = R_1 - \frac{n_1(n_1 + 1)}{2},  U_2 = R_2 - \frac{n_2(n_2 + 1)}{2}$ 
* Then the p-value is calculated from the U distribution or normal approximation.

P-values will be utilized for each statistical question listed above in order to formally analyze the data.

#### Select all that apply questions (statistical questions #2, 5, and 7)

These questions asked the participants to ‚Äúselect all that apply‚Äù as it relates to skills in pre-clinical curriculum, format of dental instruction, and skills for clinical training respectively. We will utilize frequency tables and bar plots to explore the data for these questions and use Fisher‚Äôs Exact Test as a formal inference procedure for the comparison of the two groups. Dot plots will also be utilized for questions with many options to avoid crowding in bar graphs.

Fisher‚Äôs Exact Test works with categorical data with independent samples, in this case educators and employers. Based on the survey design from the client, it is again reasonable to assume that these two groups are independent. In this context, Fisher's Exact Test is preferred over Chi-Squared Tests due to the small sample size and therefore not meeting the expected count threshold that is required to proceed with Chi-Squared Tests. Given the small sample sizes, we acknowledge the limited power of these analyses and may consider post hoc power analyses for these tests.

```{r}
#| label: fishertable
#| echo: false
#| warning: false
#| fig-cap: " "
#| fig-align: center

# Create the generic table
table_data <- data.frame(
  Group = c("Group 1 (ex: Educators)", "Group 2 (ex: Employers)", "Column Totals"),
  `Outcome Present` = c("a", "c", "a + c"),
  `Outcome Absent` = c("b", "d", "b + d"),
  `Row Totals` = c("a + b", "c + d", "n = a + b + c + d"))
  
# Print the table
kable(table_data, align = "lrr", caption = "Fisher's Exact 2√ó2 Contingency Table", booktabs=TRUE)

```

Fisher's Exact Test operates under the null hypothesis that there is no association between the two variables. The alternative hypothesis is that there is an association. The p-value for the test is computed using the following formula:

$$p = \frac{(a+b)! \, (c+d)! \, (a+c)! \, (b+d)!}{a! \, b! \, c! \, d! \, n!}$$

P-values are then computed for each skill, format, etc. between the two groups (educators and employers) depending on the statistical question to be analyzed.

#### Numerical entry questions: (statistical question #4)

This question asks participants to enter a number related to the number of dental procedures that should be completed during training in different areas. We plan to produce box plots and/or histograms to visually examine the data. Depending on the normality or lack thereof of the distributions, we will then conduct either a two-sample t-test or a Mann-Whitney U Test. As mentioned above, the Mann Whitney U test is a non-parametric test that does not depend on the assumption of normality. If the assumption on normality is met, we can consider a two-sample t test for this analysis.

# Results

## Statistical Analysis

### S1 Are there significant differences between educators and practice owners in their belief that new graduates are competent in key dental skills on their first day of practice?


To assess whether there are differences in perceptions of new graduate competence in dentistry, educators and employers were asked a parallel question (Q4). Employers were asked to rate their expectation that early career veterinarians can competently perform 12 specific dental skills on their first day of employment. Educators were asked to rate whether they believe new graduates can perform those same skills competently. Responses were recorded on a 4-point Likert scale from 1 (Strongly Disagree) to 4 (Strongly Agree).


We used the Mann-Whitney U test to compare the responses between educators and employers for each skill. This non-parametric test is appropriate for comparing ordinal data between two independent groups, especially when the assumptions for parametric tests may not hold. Ratings were reshaped into long format and analyzed skill-by-skill. Median scores and group sizes were also reported to support interpretation of the findings.

```{r}
#| label: setup_mw_test
#| echo: false
#| warning: false
#| message: false
#| include: false

library(dplyr)
library(tidyr)
library(purrr)

# Add group identifiers
educator_cleaned <- Educator_Data_Clean %>%
  mutate(group = "Educator")

employer_cleaned <- Employer_Data_Clean %>%
  mutate(group = "Employer")

# Define Q4 variable names
q4_vars <- paste0("Q04_", sprintf("%02d", 1:12))

# Subset and label
educator_q4 <- educator_cleaned %>%
  select(all_of(q4_vars)) %>%
  mutate(group = "Educator")

employer_q4 <- employer_cleaned %>%
  select(all_of(q4_vars)) %>%
  mutate(group = "Employer")

# Combine and reshape
combined_data <- bind_rows(educator_q4, employer_q4)

q4_long <- combined_data %>%
  pivot_longer(
    cols = starts_with("Q04_"),
    names_to = "Skill",
    values_to = "Rating_num"
  ) %>%
  mutate(Rating_num = as.numeric(Rating_num)) %>%
  filter(!is.na(Rating_num))

# Mann-Whitney test
mw_results <- q4_long %>%
  group_by(Skill) %>%
  summarise(
    p_value = wilcox.test(Rating_num ~ group)$p.value,
    median_educator = median(Rating_num[group == "Educator"]),
    median_employer = median(Rating_num[group == "Employer"]),
    n_educator = sum(group == "Educator"),
    n_employer = sum(group == "Employer"),
    .groups = "drop"
  ) %>%
  arrange(p_value)

# Clean column names
mw_results_clean <- mw_results %>%
  rename(
    `Skill` = Skill,
    `p-value` = p_value,
    `Median (Educator)` = median_educator,
    `Median (Employer)` = median_employer,
    `n (Educator)` = n_educator,
    `n (Employer)` = n_employer
  )

library(gt)
```

```{r}
#| label: question_1
#| echo: false
#| warning: false
#| fig-cap: " "
#| fig-align: center

mw_results_clean %>%
  gt() %>%
  tab_header(
    title = "Mann-Whitney U Test Results by Skill"
  ) %>%
  fmt_number(columns = c(`p-value`), decimals = 3)

```

### S2 Is there a difference between educators and practice owners in their reports (educators‚Äô actual teaching vs. owners‚Äô perceptions) of which dental skills were taught in the pre-clinical DVM curriculum for recent graduates?


To evaluate whether differences exist between DVM educators and employers in their understanding of which dental skills are taught in the pre-clinical curriculum, we analyzed responses to parallel survey questions. Educators were asked to indicate which of seven core dentistry skills are taught as part of their pre-clinical courses (Q12), while employers were asked which skills they believe recent graduates were taught prior to clinical training (Q16). Since the two groups answered different question numbers about the same underlying skills, we first aligned the datasets by renaming employer variables to match educator labels. This harmonization allowed for direct comparison of responses skill-by-skill across the two groups.

After cleaning and reshaping the data into long format, we filtered out invalid or missing entries and conducted Fisher‚Äôs Exact Tests for each skill. This non-parametric test is appropriate for evaluating categorical (yes/no) outcomes in small samples, especially when comparing proportions between two independent groups. Only skills for which both groups provided non-missing responses were included in the final analysis. 


```{r}
#| label: question_2prep
#| echo: false
#| warning: false
#| message: false
#| include: false
library(dplyr)
library(tidyr)

# 1. Educator Q12 data (Q12_01 to Q12_07)
educator_q12 <- Educator_Data_Clean %>%
  select(Q12_01:Q12_07) %>%
  mutate(group = "Educator")

colnames(educator_q12)[1:7] <- paste0("Q12_", sprintf("%02d", 1:7))

# 2. Employer Q16 data (only Q16_01 to Q16_10)
employer_q16 <- Employer_Data_Clean %>%
  select(Q16_01:Q16_10) %>%  # select only first 10 Q16 columns
  mutate(group = "Employer")

colnames(employer_q16)[1:10] <- paste0("Q16_", sprintf("%02d", 1:10))

# 3. Combine datasets
combined_raw <- bind_rows(educator_q12, employer_q16)

# 4. Convert Q columns to character to avoid pivot issues
combined_raw_clean <- combined_raw %>%
  mutate(across(starts_with("Q"), as.character))

# 5. Pivot longer
combined_long <- combined_raw_clean %>%
  pivot_longer(
    cols = starts_with("Q"),
    names_to = "Skill_Format",
    values_to = "Taught_raw"
  ) %>%
  mutate(
    Taught = na_if(Taught_raw, "N/A"),
    Taught = na_if(Taught, ""),
    Taught = as.numeric(Taught)
  ) %>%
  select(Skill_Format, group, Taught)

# 6. Confirm columns included
combined_long %>%
  filter(grepl("^Q16_", Skill_Format)) %>%
  distinct(Skill_Format)




combined_long %>%
  filter(grepl("^Q16_", Skill_Format)) %>%
  group_by(Skill_Format) %>%
  summarise(
    total_responses = n(),
    missing = sum(is.na(Taught)),
    non_missing = total_responses - missing,
    prop_non_missing = non_missing / total_responses
  )

# 1. Rename employer Q16 columns to Q12 labels for matching skills
employer_q16 <- Employer_Data_Clean %>%
  select(Q16_01:Q16_07) %>%
  rename_with(~ paste0("Q12_", sprintf("%02d", 1:7)), .cols = everything()) %>%
  mutate(group = "Employer")

# 2. Select educator Q12 columns and label group
educator_q12 <- Educator_Data_Clean %>%
  select(Q12_01:Q12_07) %>%
  mutate(group = "Educator")

# 3. Combine the two datasets
combined_q12_q16 <- bind_rows(educator_q12, employer_q16)

# 4. Convert Q columns to character (to avoid pivot issues)
combined_raw_clean <- combined_q12_q16 %>%
  mutate(across(starts_with("Q12_"), as.character))

# 5. Pivot to long format
combined_long <- combined_raw_clean %>%
  pivot_longer(
    cols = starts_with("Q12_"),
    names_to = "Skill_Format",
    values_to = "Taught_raw"
  ) %>%
  mutate(
    Taught = na_if(Taught_raw, "N/A"),
    Taught = na_if(Taught, ""),
    Taught = as.numeric(Taught)
  ) %>%
  filter(!is.na(Taught), group %in% c("Educator", "Employer"))

# 6. Run Fisher's exact test on valid 2x2 tables
test_results <- combined_long %>%
  group_by(Skill_Format) %>%
  summarise(
    tab = list(table(group, Taught)),
    .groups = "drop"
  ) %>%
  rowwise() %>%
  mutate(
    dims = list(dim(tab)),
    is_valid = !is.null(dims[[1]]) && all(dims[[1]] >= 2)
  ) %>%
  filter(is_valid) %>%
  mutate(
    p_value = tryCatch(fisher.test(tab)$p.value, error = function(e) NA_real_),
    n_educator = if ("Educator" %in% rownames(tab)) sum(tab["Educator", ]) else NA_integer_,
    n_employer = if ("Employer" %in% rownames(tab)) sum(tab["Employer", ]) else NA_integer_,
    prop_educator = if ("Educator" %in% rownames(tab) && "1" %in% colnames(tab)) {
      tab["Educator", "1"] / sum(tab["Educator", ])
    } else NA_real_,
    prop_employer = if ("Employer" %in% rownames(tab) && "1" %in% colnames(tab)) {
      tab["Employer", "1"] / sum(tab["Employer", ])
    } else NA_real_
  ) %>%
  ungroup() %>%
  select(-tab, -is_valid, -dims) %>%
  arrange(p_value)

```

```{r}
#| label: question_2
#| echo: false
#| warning: false
#| fig-cap: " "
#| fig-align: center

kable(test_results, 
      digits = 3,
      caption = "Fisher's Exact Test Results by Skill",
      format = "markdown")  # use "latex" for PDF, "html" for HTML output

```

### S3 Is there a difference between educators and practice owners in their level of agreement about whether specific dental skills should be taught pre-clinically?


To assess whether educators and employers differ in their beliefs about which dental skills should be included in the pre-clinical DVM curriculum, we analyzed responses to parallel Likert-scale questions: Q13 (educators) and Q17 (employers). Both groups rated the importance of teaching 12 specific dentistry skills using a 4-point Likert scale ranging from 1 (Strongly Disagree) to 4 (Strongly Agree). 

Because the data were ordinal and responses came from two independent groups, the Mann-Whitney U test was used to compare educator and employer ratings for each skill individually. This non-parametric test is appropriate for comparing ordinal data between two independent groups, especially when the assumptions for parametric tests may not hold. Ratings were reshaped into long format and analyzed skill-by-skill. 




```{r}
#| label: question_3prep
#| echo: false
#| warning: false
#| message: false
#| include: false
# Load required packages
library(dplyr)
library(tidyr)
library(gt)

# 1. Select relevant Q13 (educators) and Q17 (employers) columns
q13_vars <- paste0("Q13_", sprintf("%02d", 1:12))  # Educators
q17_vars <- paste0("Q17_", sprintf("%02d", 1:12))  # Employers

educator_q13 <- Educator_Data_Clean %>%
  select(all_of(q13_vars)) %>%
  mutate(group = "Educator")

employer_q17 <- Employer_Data_Clean %>%
  select(all_of(q17_vars)) %>%
  mutate(group = "Employer")

# 2. Combine and standardize column names
colnames(educator_q13)[1:12] <- paste0("Skill_", sprintf("%02d", 1:12))
colnames(employer_q17)[1:12] <- paste0("Skill_", sprintf("%02d", 1:12))

combined_data <- bind_rows(educator_q13, employer_q17)

# 3. Reshape to long format
q3_long <- combined_data %>%
  pivot_longer(
    cols = starts_with("Skill_"),
    names_to = "Skill",
    values_to = "Rating_num"
  ) %>%
  mutate(Rating_num = as.numeric(Rating_num)) %>%
  filter(!is.na(Rating_num))

# 4. Run Mann-Whitney U tests
q3_results <- q3_long %>%
  group_by(Skill) %>%
  summarise(
    p_value = wilcox.test(Rating_num ~ group)$p.value,
    median_educator = median(Rating_num[group == "Educator"], na.rm = TRUE),
    median_employer = median(Rating_num[group == "Employer"], na.rm = TRUE),
    n_educator = sum(group == "Educator"),
    n_employer = sum(group == "Employer"),
    .groups = "drop"
  ) %>%
  arrange(p_value)

# 5. Clean column names
q3_results_clean <- q3_results %>%
  rename(
    `p-value` = p_value,
    `Median (Educator)` = median_educator,
    `Median (Employer)` = median_employer,
    `n (Educator)` = n_educator,
    `n (Employer)` = n_employer
  )

# 6. Display results as table
q3_results_clean %>%
  gt() %>%
  tab_header(
    title = "Mann-Whitney U Test: Pre-Clinical Skill Training Beliefs"
  ) %>%
  fmt_number(columns = c(`p-value`), decimals = 3)

```

### S4 Do employers and educators differ in their expectations about how many dental procedures new graduates should complete during clinical training?

To assess whether educators and practice owners differ in their expectations for the number of dental procedures students should complete during clinical training, we compared responses from Question 19 of the educator survey and Question 24 of the employer survey. Respondents indicated the number of procedures they believe should be completed in four clinical settings: primary care, dentistry rotations, shelter medicine, and lab animal medicine. 


Before selecting an appropriate statistical test, we assessed normality using the Shapiro-Wilk test, which showed that the data were not normally distributed in any group-setting combination (all p-values < 0.05). Given the non-normal distribution and the ordinal or skewed nature of the data, we used the Mann-Whitney U test‚Äîa non-parametric alternative to the independent samples t-test‚Äîto compare the distributions of responses between educators and employers for each clinical setting. This test is appropriate when comparing two independent groups without assuming normality or equal variances.

### S5 Is there difference between the instructional formats in dentistry reported by DVM programs and the formats perceived by employers to have been completed by early career veterinarians?

Both educators and employers were asked a question relating to the format of instruction during the clinical year.

On question 20 of their survey, employers were asked: "What format of clinical instruction in dentistry do you believe that the early career veterinarians (individuals who have graduated from a DVM program after May 2021) hired into your practice/organization/institution completed as part of their DVM training? Select all that apply."

On question 16 of their survey, educators were asked: "What format of instruction in dentistry does your DVM program provide during the clinical year? Select all that apply."

Since the question was of the format "select all that apply," participants were able to select more than one response and percentages will not add to 100%. Results reported below are the percentages of their respective group (educators or employers) that selected the given format of instruction. Percentages were utilized due to the difference in sample size.

Educators and employers were also given the option to enter their own responses to the question. One employer opted to write in "Cadaver." Two educators entered their own responses with one saying "rounds" and the other saying "topic seminars do occur with some rotations during case rounds when dental cases are chosen to present."

Educators and employers differed in their perceptions of clinical dental instruction formats completed by early career veterinarians. While a majority in both groups acknowledged didactic instruction, educators reported higher rates of wet lab (73.3% vs. 46.2%) and live patient training (93.3% vs. 38.5%) compared to employers. Conversely, employers more frequently identified simulation training (30.8% vs. 16.7%) than educators. These differences suggest varying expectations or awareness between the two groups regarding dental training experiences of recent graduates.

```{r}
#| label: formatgraph
#| echo: false
#| warning: false
#| fig-cap: "Perceived Clinical Instruction Formats in Dentistry Completed by Early Career Veterinarians"
#| fig-align: center
#Add custom labels to final bar graph
option_labels <- c(
  "01" = "Didactic",
  "02" = "Simulation",
  "03" = "Wet Lab",
  "04" = "Live Patient",
  "05" = "None of these"
)

# Count total respondents per group
n_employers <- nrow(Employer_Data_Clean)
n_educators <- nrow(Educator_Data_Clean)

#Employer data: calculate percentage of total dataset
employer_percent <- Employer_Data_Clean %>%
  select(Q20_01:Q20_05) %>%
  summarise(across(everything(), ~ sum(. == 1, na.rm = TRUE))) %>%
  pivot_longer(everything(), names_to = "option", values_to = "count") %>%
  mutate(group = "Employer",
         option = str_replace(option, "Q20_", ""),
         percent = count / n_employers * 100)

#Educator data: calculate percentage of total dataset
educator_percent <- Educator_Data_Clean %>%
  select(Q16_01:Q16_05) %>%
  summarise(across(everything(), ~ sum(. == 1, na.rm = TRUE))) %>%
  pivot_longer(everything(), names_to = "option", values_to = "count") %>%
  mutate(group = "Educator",
         option = str_replace(option, "Q16_", ""),
         percent = count / n_educators * 100)

#Combine
combined_percent <- bind_rows(employer_percent, educator_percent) %>%
  mutate(option = case_when(
    option == "01" ~ "Didactic",
    option == "02" ~ "Simulation",
    option == "03" ~ "Wet Lab",
    option == "04" ~ "Live Patient",
    option == "05" ~ "None of These",
    TRUE ~ option
  ))

#Keep the order of the bars as the order of the question
combined_percent$option <- factor(combined_percent$option,
                                  levels = c("Didactic", "Simulation", "Wet Lab", "Live Patient", "None of These"))

#Plot percentages
ggplot(combined_percent, aes(x = option, y = percent, fill = group)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(title ="Dentistry Formats",
       x = "Format of Instruction",
       y = "Percent of Respondents",
       fill = "Group") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
  ylim(0, max(combined_percent$percent) + 10) +
  geom_text(aes(label = paste0(round(percent, 1), "%")), 
          position = position_dodge(width = 0.9), 
          vjust = -0.3, size = 3)
```

Figure 5.1 shows the percentages of each format selected and Table 3 shows the p-value associated with performing Fisher's Exact Test on each format.

Didactic instruction was selected by 53.3% of educators and 61.5% of employers, with no statistically significant difference between the groups (p=0.743). There was also no statistically significant difference in simulation (p=0.417) and wet lab instruction (p=0.162).

On the other hand, live patient instruction was selected by 93.3% of educators, but only 38.5% of employers. This difference was found to be statistically significant with a p-value of 0.0003.

"None of these" was also found to be statistically significant at the 5% level. No educators selected that none of these formats were used, but 23.1% of employers selected that none of the formats were believed to be utilized in the clinical year.

```{r}
#| label: question_5b
#| echo: false
#| warning: false
#| fig-cap: " "
#| fig-align: center
# Total respondents per group
n_employers <- nrow(Employer_Data_Clean)
n_educators <- nrow(Educator_Data_Clean)

# Function to get counts of selected responses
get_counts <- function(data, vars, n_total) {
  data %>%
    select(all_of(vars)) %>%
    summarise(across(everything(), ~ sum(. == 1, na.rm = TRUE))) %>%
    pivot_longer(everything(), names_to = "option", values_to = "count") %>%
    mutate(percent = count / n_total * 100,
           option = str_replace(option, "Q[0-9]+_", ""))
}

# Get counts for each group
employer_counts <- get_counts(Employer_Data_Clean, paste0("Q20_0", 1:5), n_employers)
educator_counts <- get_counts(Educator_Data_Clean, paste0("Q16_0", 1:5), n_educators)

# Merge counts by option
combined_counts <- educator_counts %>%
  rename(educator_count = count, educator_percent = percent) %>%
  inner_join(
    employer_counts %>% rename(employer_count = count, employer_percent = percent),
    by = "option"
  )

# Map option codes to labels
combined_counts <- combined_counts %>%
  mutate(Format = case_when(
    option == "01" ~ "Didactic",
    option == "02" ~ "Simulation",
    option == "03" ~ "Wet Lab",
    option == "04" ~ "Live Patient",
    option == "05" ~ "None of These"
  ))

# Calculate p-values using Fisher's Exact Test for each option
combined_counts <- combined_counts %>%
  rowwise() %>%
  mutate(
    p_value = {
      a <- educator_count
      b <- n_educators - a
      c <- employer_count
      d <- n_employers - c
      contingency_matrix <- matrix(c(a, b, c, d), nrow = 2, byrow = TRUE)
      fisher.test(contingency_matrix)$p.value
    }
  ) %>%
  ungroup()

# Select and arrange columns for output
final_table <- combined_counts %>%
  select(Format, educator_percent, employer_percent, p_value) %>%
  arrange(match(Format, c("Didactic", "Simulation", "Wet Lab", "Live Patient", "None of These")))


#Format percentages nicely
final_table <- final_table %>%
  mutate(
    educator_percent = round(educator_percent, 1),
    employer_percent = round(employer_percent, 1),
    p_value = signif(p_value, 3)
  ) %>%
  rename(
    `% of Educators Selected` = educator_percent,
    `% of Employers Selected` = employer_percent,
    `P-value` = p_value
  )

# Add significance stars
final_table <- final_table %>%
  mutate(
    Significance = case_when(
      `P-value` < 0.001 ~ "***",
      `P-value` < 0.01  ~ "**",
      `P-value` < 0.05  ~ "*",
      TRUE              ~ ""
    ),
    `P-value` = paste0(`P-value`, " ", Significance)
  ) %>%
  select(-Significance)  # Optional: remove extra column if not needed

kable(final_table, caption = "Perceived Formats of Clinical Dental Instruction in DVM Programs", align = "lrr", booktabs=TRUE)

```

### S6 Do educators and employers differ in their views on which formats of clinical instruction in dentistry should be required for DVM students as part of their clinical training?

In question #21 of the employers‚Äô version of the survey, participants were asked:

-   ‚ÄúWhich of the following types of [clinical instruction]{.underline} in dentistry do you think that DVM students should be required to complete as part of a [DVM program]{.underline}? Select one response for each of the instructional types listed below.‚Äù

The analogue of this question for educators was survey question #17, which asked:

-   ‚ÄúWhich of the following types of [instruction]{.underline} do you think DVM students should be required to complete as part of their [clinical training]{.underline}? Select one response for each type of instruction listed below.‚Äù

This question aimed to assess how participants view the types of dental instruction that should be required within veterinary medical curricula. To examine whether there were differences in opinions between educators and employers, the Mann-Whitney U-Test‚Äîa non-parametric test also known as the Wilcoxon Rank-Sum Test‚Äîwas used. This test is appropriate for comparing two independent groups without assuming a normal distribution and assumes mutual exclusivity between the groups.


```{r question_6a_updated, echo=FALSE, warning=FALSE, fig.align='center'}
# Define the matching question columns
educator_cols <- paste0("Q17_", sprintf("%02d", 1:7))
employer_cols  <- paste0("Q21_", sprintf("%02d", 1:7))

# Create human-friendly labels
instruction_labels <- c(
  "Q17_01" = "Didactic",       "Q21_01" = "Didactic",
  "Q17_02" = "Simulation",     "Q21_02" = "Simulation",
  "Q17_03" = "Wet Lab",        "Q21_03" = "Wet Lab",
  "Q17_04" = "Live Patient",   "Q21_04" = "Live Patient",
  "Q17_05" = "None of these",  "Q21_05" = "None of these",
  "Q17_06" = "Other",          "Q21_06" = "Other",
  "Q17_07" = "Other - Text",   "Q21_07" = "Other - Text"
)

# Initialize results list
mw_results <- list()

for (i in seq_along(educator_cols)) {
  q_edu <- educator_cols[i]
  q_emp <- employer_cols[i]

  edu_vals <- as.numeric(Educator_Data_Clean[[q_edu]])
  emp_vals <- as.numeric(Employer_Data_Clean[[q_emp]])

  edu_vals <- edu_vals[!is.na(edu_vals)]
  emp_vals <- emp_vals[!is.na(emp_vals)]

  if (length(edu_vals) > 1 && length(emp_vals) > 1) {
    test_result <- wilcox.test(edu_vals, emp_vals, exact = TRUE)
    mw_results[[q_edu]] <- list(
      question = q_edu,
      p_value = test_result$p.value,
      n_educators = length(edu_vals),
      n_employers = length(emp_vals)
    )
  }
}

# Create dataframe
mw_df <- do.call(rbind, lapply(mw_results, as.data.frame)) %>% as.data.frame()
mw_df$p_value <- as.numeric(mw_df$p_value)

# Add significance stars
mw_df$stars <- cut(mw_df$p_value,
                   breaks = c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
                   labels = c("***", "**", "*", ".", ""))


# Add readable labels and combine sample sizes with clear label
mw_df <- mw_df %>%
  mutate(
    Skill = recode(question, !!!instruction_labels),
    P_Value = ifelse(stars != "", paste0(sprintf("%.3f", p_value), " ", stars), sprintf("%.3f", p_value)),
    `n (educators / employers)` = paste0(n_educators, " / ", n_employers)
  ) %>%
  select(Skill, P_Value, `n (educators / employers)`)


# Render table
kable(mw_df, caption = "Mann-Whitney U-Test Results by Skill", align = "c", row.names = FALSE)
```


The results are presented in Table 7. No statistically significant differences were found between educators and employers in their responses regarding the Didactic, Simulation, or Wet Lab instructional formats. However, a significant difference was identified between the two groups concerning Live Patient instruction, where responses varied significantly. The instructional categories ‚ÄúNone of These‚Äù and ‚ÄúOther‚Äù could not be tested due to insufficient data.

### S7 Is there a difference between the clinical dentistry skills that educators report DVM students are learning during their clinical training and the skills that employers believe recent graduates have completed as part of their DVM program?

Both educators and employers were asked a question related to skills learned and practiced during the clinical year.

On question 25 of their survey, employers were asked: "Which of the following skills do you think that individuals who graduated with a DVM degree after May 2021 completed during the clinical training portion of their DVM program? Select all that apply."

On question 20 of their survey, educators were asked: "Which of the following skills are DVM students at your institution practicing/learning during the clinical training portion of the DVM program? Select all that apply."

Since the question was of the format "select all that apply," participants were able to select more than one response and percentages will not add to 100%. Results reported below are the percentages of their respective group (educators or employers) that selected the given format of instruction. Percentages were utilized due to the difference in sample size.

Educators and employers were also given the option to enter their own responses to the question. No employers entered any text responses. Six educators entered text responses of the following:

-   "OvaVet gel application, Crown amputation, Sealant application for UCF, oral tumor biopsy and excision, orthodontia"
-   "Nerve blocks, barrier sealant and bonded sealant application, jaw fracture repair, root canals"
-   "Often- bonded sealants; Sometimes- root canals, restorations, jaw fracture repair"
-   "Oral biopsy, root planning, bonded sealants"
-   "extractions only if performed on that patient"
-   "Not all students see all types of extractions"

```{r}
#| label: question_7a
#| echo: false
#| warning: false
#| fig-cap: "Clinical Training Skills Perceived by Educators vs Employers in DVM Programs"
#| fig-align: center
#| fig.width: 10
#| fig.height: 7
# Labels for each skill
option_labels <- c(
  "01" = "Oral Exam/Charting",
  "02" = "Radiographic Positioning",
  "03" = "Radiographic Interpretation",
  "04" = "Scaling",
  "05" = "Polishing",
  "06" = "Canine Closed Extraction",
  "07" = "Feline Closed Extraction",
  "08" = "Canine Open Extraction - Single Root",
  "09" = "Feline Open Extraction - Single Root",
  "10" = "Canine Open Extraction - Canines/Multiple Roots",
  "11" = "Feline Open Extraction - Canines/Multiple Roots",
  "12" = "Fluoride Treatment",
  "13" = "None of These"
)

# Respondent counts
n_employers <- nrow(Employer_Data_Clean)
n_educators <- nrow(Educator_Data_Clean)

# Valid variable names (exclude Q20_14 or Q20_NA)
valid_options <- sprintf("%02d", 1:13)
educator_vars <- paste0("Q20_", valid_options)
employer_vars <- paste0("Q25_", valid_options)

# Function to compute percent selected
get_counts <- function(data, vars, n_total) {
  data %>%
    select(all_of(vars)) %>%
    summarise(across(everything(), ~ sum(. == 1, na.rm = TRUE))) %>%
    pivot_longer(cols = everything(), names_to = "option", values_to = "count") %>%
    mutate(
      percent = count / n_total * 100,
      option = str_replace(option, "Q[0-9]+_", "")
    )
}

# Get percentages for each group
educator_percent <- get_counts(Educator_Data_Clean, educator_vars, n_educators) %>%
  mutate(Group = "Educators")

employer_percent <- get_counts(Employer_Data_Clean, employer_vars, n_employers) %>%
  mutate(Group = "Employers")

# Combine and label
combined_percent <- bind_rows(educator_percent, employer_percent) %>%
  filter(option %in% names(option_labels)) %>%
  mutate(
    Label = factor(option_labels[option], levels = rev(option_labels)),
    Group = factor(Group, levels = c("Educators", "Employers"))
  )

# Dot plot
ggplot(combined_percent, aes(x = percent, y = Label, color = Group)) +
  geom_point(aes(size = percent), alpha = 0.8) +
  geom_text(aes(label = paste0(round(percent, 1), "%")), hjust = -0.2, color = "black", fontface = "bold") +
  scale_color_manual(values = c("Educators" = "#1f78b4","Employers" = "#e31a1c"))+
  scale_size(range = c(3, 8), guide = "none") +
  labs(
    x = "% of respondents in respective groups",
    y = NULL,
    title = "Clinical Training Skills",
    subtitle = "Each dot shows percent of Eduactors or Employers who selected each skill",
    color = NULL
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "top",
    panel.grid.major.y = element_blank(),
    panel.grid.minor = element_blank(),
    plot.title = element_text(face = "bold"),
    axis.text.y = element_text(size = 10),
    plot.title.position = "plot"
  ) +
  xlim(0, max(combined_percent$percent, na.rm = TRUE) + 10)

```

```{r}
#| label: question_7b
#| echo: false
#| warning: false
#| fig-cap: " "
#| fig-align: center
# Define labels for each of the 13 skills
option_labels <- c(
  "01" = "Oral Exam/Charting",
  "02" = "Radiographic Positioning",
  "03" = "Radiographic Interpretation",
  "04" = "Scaling",
  "05" = "Polishing",
  "06" = "Canine Closed Extraction",
  "07" = "Feline Closed Extraction",
  "08" = "Canine Open Extraction - Single Root",
  "09" = "Feline Open Extraction - Single Root",
  "10" = "Canine Open Extraction - Canines/Multiple Roots",
  "11" = "Feline Open Extraction - Canines/Multiple Roots",
  "12" = "Fluoride Treatment",
  "13" = "None of These"
)

# Total respondents per group
n_employers <- nrow(Employer_Data_Clean)
n_educators <- nrow(Educator_Data_Clean)

# Generic function to summarize counts from 1s
get_counts <- function(data, vars, n_total) {
  data %>%
    select(all_of(vars)) %>%
    summarise(across(everything(), ~ sum(. == 1, na.rm = TRUE))) %>%
    pivot_longer(everything(), names_to = "option", values_to = "count") %>%
    mutate(
      percent = count / n_total * 100,
      option = str_replace(option, "Q[0-9]+_", "")  # Remove question prefix
    )
}

# Get counts for employers (Q25_01 to Q25_13)
employer_counts <- get_counts(Employer_Data_Clean, paste0("Q25_", str_pad(1:13, 2, pad = "0")), n_employers)

# Get counts for educators (Q20_01 to Q20_13)
educator_counts <- get_counts(Educator_Data_Clean, paste0("Q20_", str_pad(1:13, 2, pad = "0")), n_educators)

# Merge the two groups by skill option
combined_counts <- educator_counts %>%
  rename(educator_count = count, educator_percent = percent) %>%
  inner_join(
    employer_counts %>% rename(employer_count = count, employer_percent = percent),
    by = "option"
  )

# Add skill labels
combined_counts <- combined_counts %>%
  mutate(Skill = option_labels[option])

# Run Fisher‚Äôs Exact Test for each skill
combined_counts <- combined_counts %>%
  rowwise() %>%
  mutate(
    p_value = {
      a <- educator_count
      b <- n_educators - a
      c <- employer_count
      d <- n_employers - c
      fisher.test(matrix(c(a, b, c, d), nrow = 2, byrow = TRUE))$p.value
    }
  ) %>%
  ungroup()

# Format the final table
final_table <- combined_counts %>%
  select(Skill, educator_percent, employer_percent, p_value) %>%
  mutate(
    educator_percent = round(educator_percent, 1),
    employer_percent = round(employer_percent, 1),
    p_value = signif(p_value, 3)
  ) %>%
  rename(
    `% of Educators` = educator_percent,
    `% of Employers` = employer_percent,
    `P-value` = p_value
  ) %>%
  arrange(match(Skill, option_labels))

# Add significance stars
final_table <- final_table %>%
  mutate(
    Significance = case_when(
      `P-value` < 0.001 ~ "***",
      `P-value` < 0.01  ~ "**",
      `P-value` < 0.05  ~ "*",
      TRUE              ~ ""
    ),
    `P-value` = paste0(`P-value`, " ", Significance)
  ) %>%
  select(-Significance)  # Optional: remove extra column if not needed


# Print a clean table
kable(final_table, caption = "Perceived Skills Learned of Clinical Dental Instruction in DVM Programs", align = "lrr", booktabs=TRUE)
```

Figure 5.2 shows the percentage of employers and educators who selected the given skills and Table 4 shows the p-values associated with Fisher's Exact Test and their significance.

For eleven of the thirteen skills, educators reported a higher percentage of selection. The two skills for which employers reported higher perceived learning were feline open extraction - canines/multiple roots and fluoride treatment.

At the 5% significance level, the difference in skill selection between employers and educators was found to be significant for seven skills:

-   Scaling
-   Polishing
-   Canine Closed Extraction
-   Feline Closed Extraction
-   Canine Open Extraction - Single Root
-   Feline Open Extraction - Single Root
-   Canine Open Extraction - Canines/Multiple Roots

For all skills with statistically significant differences, educators reported higher percentages than employers.

The most significant difference was found in polishing. Educators selected this skill 76.7% of the time, while employers selected this skill only 30.8% of the time. The resulting p-value was 0.00672.

### S8 Do educators and employers differ in their opinions about which clinical dentistry skills DVM students should be required to practice or learn during their clinical training?

In question #26 of the employers‚Äô version of the survey, participants were asked:

* ‚ÄúWhich of the following skills do you think that DVM students should be required to practice/learn as part of the clinical training portion of a DVM program? Select one response for each of the skills listed below.‚Äù

The corresponding question for educators was survey question #21.

This question aimed to assess opinions on which clinical dentistry skills should be required in DVM student training. To evaluate whether differences existed between educators and employers, the Mann-Whitney U-Test, a non-parametric test also known as the Wilcoxon Rank-Sum Test, was applied. This test compares two independent groups without assuming normality and requires mutual exclusivity between groups.

The results are presented in Table 9. No statistically significant differences were observed between educators and employers for most of the listed clinical skills, including oral examination/charting, radiographic positioning, radiographic interpretation, scaling, polishing, or several extraction procedures. However, significant differences were identified for the skills of feline closed extraction and canine open extraction‚Äîsingle root, with p-values of 0.049 for both. Two additional procedures‚Äîfeline open extraction‚Äîsingle root and canine open extraction‚Äîcanines/multiple roots‚Äîapproached significance (p = 0.076). The ‚ÄúFluoride treatment‚Äù and ‚ÄúNone‚Äù categories could not be tested due to insufficient data.

```{r question_8a, echo=FALSE, warning=FALSE, fig.align='center'}
# Define educator and employer question columns (first 13 only)
educator_cols <- paste0("Q21_", sprintf("%02d", 1:13))
employer_cols <- paste0("Q26_", sprintf("%02d", 1:13))

# Create human-friendly labels (first 13 procedures only)
procedure_labels <- c(
  "Oral exam/charting",
  "Radiographic positioning",
  "Radiographic interpretation",
  "Scaling",
  "Polishing",
  "Canine closed extraction",
  "Feline closed extraction",
  "Canine open extraction - Single root",
  "Feline open extraction - Single root",
  "Canine open extraction - Canines/multiple roots",
  "Feline open extraction - Canines/multiple roots",
  "Fluoride treatment",
  "None"
)

names(procedure_labels) <- educator_cols

# Initialize results list
mw_results <- list()

for (i in seq_along(educator_cols)) {
  q_edu <- educator_cols[i]
  q_emp <- employer_cols[i]
  
  edu_vals <- as.numeric(Educator_Data_Clean[[q_edu]])
  emp_vals <- as.numeric(Employer_Data_Clean[[q_emp]])
  
  edu_vals <- edu_vals[!is.na(edu_vals)]
  emp_vals <- emp_vals[!is.na(emp_vals)]
  
  if (length(edu_vals) > 1 && length(emp_vals) > 1) {
    test_result <- wilcox.test(edu_vals, emp_vals, exact = TRUE)
    mw_results[[q_edu]] <- list(
      Instruction_Type = procedure_labels[[q_edu]],
      W_Statistic = round(test_result$statistic, 1),
      P_Value = round(test_result$p.value, 3)
    )
  } else {
    mw_results[[q_edu]] <- list(
      Instruction_Type = procedure_labels[[q_edu]],
      W_Statistic = "-",
      P_Value = "-"
    )
  }
}

# Combine results into a data frame
mw_df <- do.call(rbind, lapply(mw_results, as.data.frame)) %>% as.data.frame()

# Add significance and notes
mw_df <- mw_df %>%
  mutate(
    Significance = case_when(
      P_Value == "-" ~ "-",
      as.numeric(P_Value) <= 0.001 ~ "***",
      as.numeric(P_Value) <= 0.01 ~ "**",
      as.numeric(P_Value) <= 0.05 ~ "*",
      as.numeric(P_Value) <= 0.1 ~ ".",
      TRUE ~ "ns"
    ),
    Notes = ifelse(P_Value == "-", "Insufficient data", "Test performed")
  )

# Remove rownames before table
rownames(mw_df) <- NULL

# Render kable table
kable(mw_df, caption = "Mann-Whitney U-Test Results for Clinical Procedures", align = "c")
```

# Discussion/Conclusion

## Interpretation of Results

```{r question_6a, , echo=FALSE, eval=FALSE, warning=FALSE, fig.align='center'}
# Define the matching question columns
educator_cols <- paste0("Q17_", sprintf("%02d", 1:7))
employer_cols  <- paste0("Q21_", sprintf("%02d", 1:7))

# Create human-friendly labels
instruction_labels <- c(
  "Q17_01" = "Didactic",       "Q21_01" = "Didactic",
  "Q17_02" = "Simulation",     "Q21_02" = "Simulation",
  "Q17_03" = "Wet Lab",        "Q21_03" = "Wet Lab",
  "Q17_04" = "Live Patient",   "Q21_04" = "Live Patient",
  "Q17_05" = "None of these",  "Q21_05" = "None of these",
  "Q17_06" = "Other",          "Q21_06" = "Other",
  "Q17_07" = "Other - Text",          "Q21_07" = "Other - Text"
)



# Initialize an empty list to store results
mw_results <- list()

for (i in seq_along(educator_cols)) {
  q_edu <- educator_cols[i]
  q_emp <- employer_cols[i]
  
  edu_vals <- as.numeric(Educator_Data_Clean[[q_edu]])
  emp_vals <- as.numeric(Employer_Data_Clean[[q_emp]])
  
  edu_vals <- edu_vals[!is.na(edu_vals)]
  emp_vals <- emp_vals[!is.na(emp_vals)]
  
  if (length(edu_vals) > 1 && length(emp_vals) > 1) {
    test_result <- wilcox.test(edu_vals, emp_vals, exact = TRUE)
    mw_results[[q_edu]] <- list(
      question = q_edu,
      W = test_result$statistic,
      p_value = test_result$p.value
    )
  } else {
    mw_results[[q_edu]] <- list(
      question = q_edu,
      W = NA,
      p_value = NA
    )
  }
}

# Create mw_df
mw_df <- do.call(rbind, lapply(mw_results, as.data.frame)) %>% as.data.frame()
mw_df$p_value <- as.numeric(mw_df$p_value)
mw_df$W <- as.numeric(mw_df$W)
mw_df$question <- rownames(mw_df)
mw_df$significance <- cut(mw_df$p_value,
                          breaks = c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
                          labels = c("***", "**", "*", ".", "ns"))

# Build display table with readable names
mw_table <- mw_df %>%
  filter(question != "Q17_07") %>%
  mutate(
    Instruction_Type = recode(question, !!!instruction_labels),
    W_Statistic = ifelse(is.na(W), "-", round(W, 1)),
    P_Value = ifelse(is.na(p_value), "-", round(p_value, 3)),
    Significance = ifelse(is.na(significance), "-", as.character(significance)),
    Notes = ifelse(P_Value == "-", "Insufficient data", "Test performed")
  ) %>%
  select(Instruction_Type, W_Statistic, P_Value, Significance, Notes)  # No 'question' column here


# ====================
# Now the Plot Section
# ====================

# Educator data (remove Q17_05 and Q17_06)
educator_long <- Educator_Data_Clean %>%
  select(starts_with("Q17_")) %>%
  select(-Q17_05, -Q17_06) %>%
  pivot_longer(cols = everything(), names_to = "question", values_to = "response") %>%
  mutate(group = "Educator")

# Employer data (remove Q21_05 and Q21_06)
employer_long <- Employer_Data_Clean %>%
  select(starts_with("Q21_")) %>%
  select(-Q21_05, -Q21_06) %>%
  pivot_longer(cols = everything(), names_to = "question", values_to = "response") %>%
  mutate(group = "Employer")


# Combine and apply instruction labels
plot_data <- bind_rows(educator_long, employer_long) %>%
  mutate(response = as.numeric(response)) %>%
  filter(!is.na(response)) %>%
  mutate(question = recode(question, !!!instruction_labels))

desired_order <- c("Live Patient", "Wet Lab", "Didactic", "Simulation")
plot_data <- plot_data %>%
  filter(question %in% desired_order) %>%
  mutate(question = factor(question, levels = desired_order))


plot_summary <- plot_data %>%
  group_by(question, response, group) %>%
  summarize(count = n(), .groups = "drop") %>%
  # Make counts negative for one group to diverge left
  mutate(count_signed = ifelse(group == "Employer", -count, count))

# Plot horizontal diverging bars
ggplot(plot_summary, aes(x = factor(response), y = count_signed, fill = group)) +
  geom_bar(stat = "identity", color = "black", width = 0.7) +
  coord_flip() +
  facet_wrap(~ question, ncol = 2) +
  scale_y_continuous(
    breaks = scales::pretty_breaks(),
    labels = abs
  ) +
  labs(
    title = "Horizontal Diverging Bar Chart: Educator vs Employer Responses",
    x = "Response Level",
    y = "Count",
    fill = "Group"
  ) +
  theme_minimal() +
  scale_fill_manual(values = c("Educator" = "#1f77b4", "Employer" = "#ff7f0e"))
```



## Implications of the Study

## Limitations

## Recommendations

## Summary of Key Findings

## Final Thoughts

# Appendix


