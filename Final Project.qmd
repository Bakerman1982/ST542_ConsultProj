---
title: "Bridging the Gap:"
subtitle: "Comparing Employer and Educator Expectations in Small Animal Dentistry"
author: Brock Akerman, Hanan Ali, Taylor Cesarski
date: "June, 25, 2025"
format:
  pdf:
    pdf-engine: xelatex
    mainfont: "Times New Roman"
    toc: true
    toc-depth: 2
    number-sections: true
    fig-align: center
    fig-cap-location: top
    fig-pos: 'H'
    geometry: margin=1in
    fontsize: 11pt
    keep-tex: true
    linkcolor: blue
---

```{r package_load, warning=FALSE, include=FALSE}
library(ggplot2)
library(tidyverse)
library(janitor)
library(gtools)
library(naniar)
```

```{r Employer Data load, echo=FALSE, message=FALSE, warning=FALSE, results="hide",include=FALSE, error=FALSE}
#############################################
## Connect, Import, group and primary key. ##
#############################################

#Read data into R environment. 
Employer_Data <- read_csv("Employer_Dentistry_Survey.csv") %>% clean_names()
#Name new object to work with leaving original intact/untouched
Employer_Data_Clean <- Employer_Data

#Add grouping identifier now so if we combine data later, we have our groups delineated. 
Employer_Data_Clean <- Employer_Data_Clean %>%
  mutate(
    group = "Employer", #Categorizes all responses as Employer
    respondent_id = row_number() #Maintains respondent ID
  )


############################
#####  DATA WRANGLING  #####
############################

#Adjust headers for readability and add grouping identifier.
#1.) Remove redundancy in column names, 
#2.) Replace "quid" with "Q", and
#3.) All "_text" with "T".
colnames(Employer_Data_Clean) <- gsub("_text$", "_T", gsub("q", "Q", colnames(Employer_Data_Clean)))
#4.) Format the column headers so that it is sort-able both by question and sub question. So where 
#questions are formatted with header Q10_2, the header will now be Q10_02.  This preserves ordering
#and makes indexing easier. 
emp_pad_question_ids <- function(col_names) {
  col_names %>%
    str_replace_all("Q(\\d{1})(?!\\d)", "Q0\\1") %>%
    str_replace_all("Q(\\d{2})_(\\d{1})(?!\\d)", "Q\\1_0\\2")}

#Apply above formatting changes to data frame column names
colnames(Employer_Data_Clean) <- emp_pad_question_ids(colnames(Employer_Data_Clean))

#Removes Qualtric metadata from the first two rows
Employer_Data_Clean <- Employer_Data_Clean %>% slice(-1, -2)



### QUESTION-BY-QUESTION Cleaning

#------------
#Question #04
#------------
#Renames the text response to index 13 and places it in its order. 
Employer_Data_Clean <- Employer_Data_Clean %>%
  rename(Q04_13 = Q04_12_T)

#------------
#Question #09 does not need correcting. 
#------------

#------------
#Question #16
#------------
#Renames the text response to index 11 and places it in its order. 
Employer_Data_Clean <- Employer_Data_Clean %>%
  rename(Q16_11 = Q16_10_T) 

#Process Q12: Split responses and pivot to wide format
Employer_Data_Clean <- Employer_Data_Clean %>%
  mutate(respondent_id = row_number()) %>%
  separate_rows(Q16, sep = ",") %>%
  mutate(Q16 = str_trim(Q16)) %>%
  #filter(!is.na(Q16)) %>%  # üîß prevent Q16_NA column in pivot_wider
  mutate(Q16 = str_pad(Q16, width = 2, pad = "0"),
         value = 1) %>%
  pivot_wider(
    names_from = Q16,
    names_prefix = "Q16_",
    values_from = value,
    values_fill = 0
  ) %>%
  right_join(select(Employer_Data_Clean, respondent_id), by = "respondent_id")  # üîÅ bring back NA responders


if (!"Q16_09" %in% colnames(Employer_Data_Clean)) {
  Employer_Data_Clean$Q16_09 <- 0
}


#------------
#Question #17
#------------
#Renames the text response to index 14 and places it in its order.
Employer_Data_Clean <- Employer_Data_Clean %>%
  rename(Q17_15 = Q17_14_T)

#------------
#Question #20
#------------
# Create binary indicator columns from Q16.  Recall that Q16 was a multiple responsive
# "Select all that Apply" question where participants could choose however many they 
# wanted.  In the Qualtrics output, these responses were comma-separated.  This query
# breaks each reponse out over a column and assigns values of "0" or "1" depending on 
# whether they choose that particular response. The same issue is address in Question #20. 
Q20_binary <- Employer_Data_Clean %>%
  select(respondent_id, Q20) %>%
  separate_rows(Q20, sep = ",") %>%
  mutate(Q20 = str_trim(Q20)) %>%
  #filter(!is.na(Q20)) %>%   # üëà Prevents Q20_NA from being created
  mutate(Q20 = str_pad(Q20, width = 2, pad = "0"),
         value = 1) %>%
  pivot_wider(
    names_from = Q20,
    names_prefix = "Q20_",
    values_from = value,
    values_fill = 0
  ) %>%
  right_join(select(Employer_Data_Clean, respondent_id), by = "respondent_id")

# Remove the old Q16 columns and join the binary ones on respondent_id
Employer_Data_Clean <- Employer_Data_Clean %>%
  select(-Q20) %>%
  left_join(Q20_binary, by = "respondent_id")

# Renames the text response to index 07 and places it in its order.
Employer_Data_Clean <- Employer_Data_Clean %>%
  rename(Q20_07 = Q20_06_T) %>%
  relocate(Q20_07, .after = Q20_06)

# Add Q16_05 as a column of zeros if it doesn't exist (it does not)
if (!"Q20_05" %in% colnames(Employer_Data_Clean)) {
  Employer_Data_Clean$Q20_05 <- 0
}

#------------
#Question #21
#------------
#Renames the text response to index 07 and places it in its order.
Employer_Data_Clean <- Employer_Data_Clean %>%
  rename(Q21_07 = Q21_06_T) 

#------------
#Question #22 does not need correcting. 
#------------

#------------
#Question #24 does not need correcting. 
#------------

#------------
#Question #25
#------------
# Create binary indicator columns from Q25.  Recall that Q25 was a multiple responsive
# "Select all that Apply" question where participants could choose however many they 
# wanted.  In the Qualtrics output, these responses were comma-separated.  This query
# breaks each reponse out over a column and assigns values of "0" or "1" depending on 
# whether they choose that particular response. The same issue is address in Question #16. 
Q25_binary <- Employer_Data_Clean %>%
  select(respondent_id, Q25) %>%
  separate_rows(Q25, sep = ",") %>%
  mutate(Q25 = str_trim(Q25)) %>%
  #filter(!is.na(Q25)) %>%   # üëà Prevents Q25_NA
  mutate(Q25 = str_pad(Q25, width = 2, pad = "0"),
         value = 1) %>%
  pivot_wider(
    names_from = Q25,
    names_prefix = "Q25_",
    values_from = value,
    values_fill = 0
  ) %>%
  right_join(select(Employer_Data_Clean, respondent_id), by = "respondent_id")


# Remove the old Q16 columns and join the binary ones in
Employer_Data_Clean <- Employer_Data_Clean %>%
  select(-Q25) %>%
  left_join(Q25_binary, by = "respondent_id")

# Add Q25_13 as a column of zeros if it doesn't exist (it does not)
if (!"Q25_13" %in% colnames(Employer_Data_Clean)) {
  Employer_Data_Clean$Q25_13 <- 0
}

# Rename and relocate the "Other" text entry for Q16
Employer_Data_Clean <- Employer_Data_Clean %>%
  rename(Q25_14 = Q25_13_T) %>%
  relocate(Q25_14, .after = Q25_13)

#------------
#Question #26
#------------
#Renames the text response to index 14 and places it in its order. 
Employer_Data_Clean <- Employer_Data_Clean %>%
  rename(Q26_14 = Q26_13_T) 


##########################
##### FILTER DATASET #####
##########################
#"Q20_NA"
#"Q25_NA"


#Remove irrelevant/problematic columns to the research/stats questions
Employer_Data_Clean <- Employer_Data_Clean %>%
  mutate(progress = as.numeric(progress)) %>%
  filter(Q02 == '1', progress >= 50) %>%
  select(
    ip_address, progress, duration_in_seconds,
    finished, recorded_date, response_id, group, respondent_id,
    starts_with("Q04"),
    starts_with("Q09"),
    starts_with("Q16"),
    starts_with("Q17"),
    starts_with("Q20"),
    starts_with("Q21"),
    starts_with("Q22"),
    starts_with("Q24"),
    starts_with("Q25"),
    starts_with("Q26"),
    -Q16_NA,  # üëà drop this
    -Q20_NA,  # üëà drop this
    -Q25_NA
  )

#Identify metadata columns to keep at the front
emp_meta_cols <- c("ip_address", "progress", "duration_in_seconds",
               "finished", "recorded_date", "response_id", "group", "respondent_id")

#Identify and sort Q columns using mixedsort
emp_q_cols <- setdiff(colnames(Employer_Data_Clean), emp_meta_cols)
emp_q_cols_sorted <- mixedsort(emp_q_cols)

#Reorder the data frame
Employer_Data_Clean <- Employer_Data_Clean[, c(emp_meta_cols, emp_q_cols_sorted)]
```

```{r Educator Data load, echo=FALSE, message=FALSE, warning=FALSE, results="hide",include=FALSE, error=FALSE}
#############################################
## Connect, Import, group and primary key. ##
#############################################

#Read data into R environment. 
Educator_Data <- read_csv("PCVE_Dentistry_Survey.csv") %>% clean_names()
#Name new object to work with leaving original intact/untouched
Educator_Data_Clean <- Educator_Data

#Add identifier affirming educator responses. 
Educator_Data_Clean <- Educator_Data_Clean %>%
  mutate(
    group = "Educator",
    respondent_id = row_number()
  )

############################
#####  DATA WRANGLING  #####
############################

#Adjust headers for readability and add grouping identifier.
  #1.) Remove redundancy in column names, 
  #2.) Replace "quid" with "Q", and
  #3.) All "_text" with "T".
colnames(Educator_Data_Clean) <- gsub("_text$", "_T", gsub("q", "Q", colnames(Educator_Data_Clean)))
  #4.) Format the column headers so that it is sort-able both by question and sub question. So where 
    #questions are formatted with header Q10_2, the header will now be Q10_02.  This preserves ordering
    #and makes indexing easier. 
edu_pad_question_ids <- function(col_names) {
  col_names %>%
    str_replace_all("Q(\\d{1})(?!\\d)", "Q0\\1") %>%
    str_replace_all("Q(\\d{2})_(\\d{1})(?!\\d)", "Q\\1_0\\2")}

#Apply above formatting changes to data frame column names
colnames(Educator_Data_Clean) <- edu_pad_question_ids(colnames(Educator_Data_Clean))

#Removes Qualtric metadata from the first two rows
Educator_Data_Clean <- Educator_Data_Clean %>% slice(-1, -2)


### QUESTION-BY-QUESTION Cleaning

#------------
#Question #04
#------------
#Renames the text response to index 13 and places it in its order. 
Educator_Data_Clean <- Educator_Data_Clean %>%
  rename(Q04_13 = Q04_12_T)

#------------
#Question #07 does not need correcting. 
#------------

#------------
#Question #12
#------------
  #Renames the text response to index 11 and places it in its order. 
Educator_Data_Clean <- Educator_Data_Clean %>%
  rename(Q12_11 = Q12_10_T) 

  #Process Q12: Split responses and pivot to wide format
Educator_Data_Clean <- Educator_Data_Clean %>%
  # Create a temporary respondent ID if not already done
  mutate(respondent_id = row_number()) %>%
  # Separate comma-separated values into long format
  separate_rows(Q12, sep = ",") %>%
  # Trim whitespace if any
  mutate(Q12 = str_trim(Q12)) %>%
  # Pad values with leading zero for consistent column naming (01, 02, ..., 11)
  mutate(Q12 = str_pad(Q12, width = 2, pad = "0"),
         value = 1) %>%
  # Pivot wider to get binary indicator columns
  pivot_wider(
    names_from = Q12,
    names_prefix = "Q12_",
    values_from = value,
    values_fill = 0
  )

#------------
#Question #13
#------------
#Renames the text response to index 14 and places it in its order.
Educator_Data_Clean <- Educator_Data_Clean %>%
  rename(Q13_14 = Q13_13_T)

#------------
#Question #16
#------------
# Create binary indicator columns from Q16.  Recall that Q16 was a multiple responsive
# "Select all that Apply" question where participants could choose however many they 
# wanted.  In the Qualtrics output, these responses were comma-separated.  This query
# breaks each reponse out over a column and assigns values of "0" or "1" depending on 
# whether they choose that particular response. The same issue is address in Question #20. 
Q16_binary <- Educator_Data_Clean %>%
  select(respondent_id, Q16) %>%
  separate_rows(Q16, sep = ",") %>%
  mutate(Q16 = str_trim(Q16)) %>%
  mutate(Q16 = str_pad(Q16, width = 2, pad = "0"),
         value = 1) %>%
  pivot_wider(
    names_from = Q16,
    names_prefix = "Q16_",
    values_from = value,
    values_fill = 0
  )

  # Remove the old Q16 columns and join the binary ones on respondent_id
Educator_Data_Clean <- Educator_Data_Clean %>%
  select(-Q16) %>%
  left_join(Q16_binary, by = "respondent_id")

  # Renames the text response to index 07 and places it in its order.
Educator_Data_Clean <- Educator_Data_Clean %>%
  rename(Q16_07 = Q16_06_T) %>%
  relocate(Q16_07, .after = Q16_06)

  # Add Q16_05 as a column of zeros if it doesn't exist (it does not)
if (!"Q16_05" %in% colnames(Educator_Data_Clean)) {
  Educator_Data_Clean$Q16_05 <- 0
}

#------------
#Question #17
#------------
#Renames the text response to index 07 and places it in its order.
Educator_Data_Clean <- Educator_Data_Clean %>%
  rename(Q17_07 = Q17_06_T) 

#------------
#Question #18 does not need correcting. 
#------------

#------------
#Question #19 does not need correcting. 
#------------

#------------
#Question #20
#------------
# Create binary indicator columns from Q16.  Recall that Q16 was a multiple responsive
# "Select all that Apply" question where participants could choose however many they 
# wanted.  In the Qualtrics output, these responses were comma-separated.  This query
# breaks each reponse out over a column and assigns values of "0" or "1" depending on 
# whether they choose that particular response. The same issue is address in Question #16. 
Q20_binary <- Educator_Data_Clean %>%
  select(respondent_id, Q20) %>%
  separate_rows(Q20, sep = ",") %>%
  mutate(Q20 = str_trim(Q20)) %>%
  mutate(Q20 = str_pad(Q20, width = 2, pad = "0"),
         value = 1) %>%
  pivot_wider(
    names_from = Q20,
    names_prefix = "Q20_",
    values_from = value,
    values_fill = 0
  )

# Remove the old Q16 columns and join the binary ones in
Educator_Data_Clean <- Educator_Data_Clean %>%
  select(-Q20) %>%
  left_join(Q20_binary, by = "respondent_id")

# Rename and relocate the "Other" text entry for Q16
Educator_Data_Clean <- Educator_Data_Clean %>%
  rename(Q20_14 = Q20_13_T) %>%
  relocate(Q20_14, .after = Q20_13)

#------------
#Question #21
#------------
#Renames the text response to index 14 and places it in its order. 
Educator_Data_Clean <- Educator_Data_Clean %>%
  rename(Q21_14 = Q21_13_T) 


##########################
##### FILTER DATASET #####
##########################

#Remove irrelevant/problematic columns to the research/stats questions
Educator_Data_Clean <- Educator_Data_Clean %>%
  mutate(progress = as.numeric(progress)) %>%
  filter(Q44 != "2", progress >= 50) %>%
  select(
    ip_address, progress, duration_in_seconds,
    finished, recorded_date, response_id, group, respondent_id,
    starts_with("Q04"),
    starts_with("Q07"),
    starts_with("Q12"),
    starts_with("Q13"),
    starts_with("Q16"),
    starts_with("Q17"),
    starts_with("Q18"),
    starts_with("Q19"),
    starts_with("Q20"),
    starts_with("Q21")
  )



#Identify metadata columns to keep at the front
edu_meta_cols <- c("ip_address", "progress", "duration_in_seconds",
               "finished", "recorded_date", "response_id", "group", "respondent_id")

#Identify and sort Q columns using mixedsort
edu_q_cols <- setdiff(colnames(Educator_Data_Clean), edu_meta_cols)
edu_q_cols_sorted <- mixedsort(edu_q_cols)

#Reorder the data frame
Educator_Data_Clean <- Educator_Data_Clean[, c(edu_meta_cols, edu_q_cols_sorted)]
```

## Abstract

## Introduction

### Purpose of project

### Study details

## Data

### Data Description

Two separate surveys were administered to mutually exclusive groups: veterinary employers who have worked with students, and educators who have taught those students. There was no overlap between these groups‚Äîno evidence suggests that any surveyed student was both taught by an educator and later employed by a participating employer.

The employer dataset consists of responses from 29 participants, while the educator dataset includes 43 participants. This difference in response count suggests greater willingness among educators to engage with the survey.

Additionally, survey completion time differed between groups. Educators, on average, spent more time completing the survey than employers. While the survey did not ask participants to explain their response time, this difference may reflect greater engagement or the tendency for more elaborated responses among educators. A box plot below illustrates the distribution of survey duration (in minutes) by group.

```{r Data_Desc_01, echo=FALSE, fig.align='center'}
#Average time for survey completion
# Convert and clean both datasets
clean_employer <- Employer_Data[-c(1,2), ] %>%
  mutate(
    duration_in_seconds = as.numeric(duration_in_seconds),
    duration_minutes = duration_in_seconds / 60,
    group = "Employer"
  )

clean_educator <- Educator_Data[-c(1,2), ] %>%
  mutate(
    duration_in_seconds = as.numeric(duration_in_seconds),
    duration_minutes = duration_in_seconds / 60,
    group = "Educator"
  )

# Combine for optional single-geom plotting, or keep separate for layers
ggplot() +
  geom_boxplot(data = clean_employer,
               aes(x = group, y = duration_minutes),
               fill = "steelblue", alpha = 0.6) +
  geom_boxplot(data = clean_educator,
               aes(x = group, y = duration_minutes),
               fill = "darkorange", alpha = 0.6) +
  coord_cartesian(ylim = c(0, 80)) +  # Optional: zoom to 0‚Äì60 minutes
  labs(
    title = "Survey Completion Time by Group",
    x = "Respondent Group",
    y = "Duration (minutes)"
  ) +
  theme_minimal()
```

Regarding the proportion of the survey completed, employer responses were more variable‚Äîspanning the full range from partial to full completion. In contrast, educators tended to complete more of the survey, with a concentration near full completion and a less pronounced left tail. The density plot below visualizes these differences in survey progress across groups.

```{r Data_Desc_02, echo=FALSE, fig.align='center'}
#Average percent of survey completed
combined_progress <- bind_rows(
  Employer_Data[-c(1,2), ] %>% mutate(group = "Employer"),
  Educator_Data[-c(1,2), ] %>% mutate(group = "Educator")
) %>%
  mutate(progress = as.numeric(progress))

ggplot(combined_progress, aes(x = progress, fill = group)) +
  geom_density(alpha = 0.4) +
  labs(title = "Survey Progress Density by Group", x = "Progress (%)", y = "Density") +
  theme_minimal()

```

From the educators dataset we could talk about:
* Q27; How long have you been teaching DVM students in the clinical training portion of a DVM program?
* Q28; Does your institution have a teaching hospital?
* Q29; On average, how many dental procedures does your primary care service perform each week?

From the employers dataset we could talk about:
* Q33; Which of the following best describes your job setting or organization?
* Q36; On average, how many dental procedures does your practice/oganization/institution perform each week
* Q37; Which of the following best describes the person who completed this survey?

```{r Data_Desc_03, fig.align='center'}

```


```{r Data_Desc_04, fig.align='center'}

```


### Data Source

Survey data were collected using Qualtrics, a cloud-based experience management platform commonly used for gathering feedback and sentiment across workforce domains. Participants were recruited via email invitation sent by the researcher, using pre-existing contact lists. Participation was voluntary and anonymized.

### Preprocessing Description

Although the employer and educator datasets shared a similar structure, they were not identical. Most preprocessing steps were applied uniformly across both datasets, with minor deviations where needed.

The datasets were imported into the RStudio environment (version 2024.04.1 Build 748). A new variable was created to label the data source ("Educator" or "Employer") for later grouping and visualization. The existing respondent_id column served as a unique identifier and was treated as the primary key.

Initial cleaning involved removing extraneous metadata included by Qualtrics‚Äîsuch as survey start and end times, IP addresses, geolocation data, and question display logic‚Äîall of which were irrelevant to the analysis. These columns were trimmed to streamline the dataset for subsequent transformation and statistical work.

Column names in the original Qualtrics export were alphanumeric but often ambiguous and misleading. Many variable names did not match the corresponding survey question numbers. Our team manually mapped the exported column names to their corresponding survey questions and responses by referencing adjacent metadata fields and using deductive reasoning. This process allowed us to build an index-based column naming structure, which greatly improved the manageability and interpretability of the dataset.

Before diving into question-specific analysis, we first identified the subset of survey questions relevant to our research objectives. All unrelated or out-of-scope items were removed. This step reduced the employer dataset from 176 columns to 100, and the educator dataset from 171 columns to 102.

Several formatting inconsistencies also needed to be resolved. Some multi-select questions appeared in the form of comma-separated text responses within a single column, while others were exported into multiple binary columns. Additionally, for certain questions, a response option that received zero selections was dropped entirely by Qualtrics. To standardize these issues, we implemented a script to ‚Äúexplode‚Äù comma-separated responses into individual binary columns. For dropped columns, we manually reintroduced them as zero-filled dummy variables to preserve the full response structure.

Finally, we filtered out participants who answered less than half of the survey. We also excluded:

-   Employers who responded ‚ÄúNo‚Äù to the question: ‚ÄúDo you work with early career veterinarians (someone who has graduated from a DVM program after May 2021)?‚Äù

-   Educators who responded ‚ÄúNo‚Äù to: ‚ÄúDo you teach in any capacity of the dental curriculum at your institution?‚Äù

After all preprocessing steps, the final cleaned datasets consisted of 13 employer participants and 30 educator participants.


## Statistical Methods

### Research Question Answered

### Method Description

## Results

### Findings

### Statistical Analysis

## Discussion/Conclusion

### Interpretation of Results

### Implications of the Study

### Limitations

### Recommendations

### Summary of Key Findings

### Final Thoughts

## Appendix
